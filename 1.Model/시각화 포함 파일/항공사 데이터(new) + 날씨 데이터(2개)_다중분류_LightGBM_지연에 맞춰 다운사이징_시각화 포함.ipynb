{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0b17508",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-22T08:36:45.142611Z",
     "start_time": "2026-01-22T08:36:01.578318Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_14512\\427178239.py:9: DtypeWarning: Columns (29,50) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"new_flight_weather_merged.csv\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\envs\\4vector\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_14512\\427178239.py\", line 9, in <module>\n",
      "    df = pd.read_csv(\"new_flight_weather_merged.csv\")\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\envs\\4vector\\lib\\site-packages\\pandas\\util\\_decorators.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\envs\\4vector\\lib\\site-packages\\pandas\\util\\_decorators.py\", line 331, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\envs\\4vector\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\", line 950, in read_csv\n",
      "    return _read(filepath_or_buffer, kwds)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\envs\\4vector\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\", line 611, in _read\n",
      "    return parser.read(nrows)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\envs\\4vector\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\", line 1795, in read\n",
      "    df = DataFrame(col_dict, columns=columns, index=index)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\envs\\4vector\\lib\\site-packages\\pandas\\core\\frame.py\", line 664, in __init__\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\envs\\4vector\\lib\\site-packages\\pandas\\core\\internals\\construction.py\", line 493, in dict_to_mgr\n",
      "    return arrays_to_mgr(arrays, columns, index, dtype=dtype, typ=typ, consolidate=copy)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\envs\\4vector\\lib\\site-packages\\pandas\\core\\internals\\construction.py\", line 154, in arrays_to_mgr\n",
      "    return create_block_manager_from_column_arrays(\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\envs\\4vector\\lib\\site-packages\\pandas\\core\\internals\\managers.py\", line 2199, in create_block_manager_from_column_arrays\n",
      "    blocks = _form_blocks(arrays, consolidate)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\envs\\4vector\\lib\\site-packages\\pandas\\core\\internals\\managers.py\", line 2273, in _form_blocks\n",
      "    values, placement = _stack_arrays(list(tup_block), dtype)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\envs\\4vector\\lib\\site-packages\\pandas\\core\\internals\\managers.py\", line 2312, in _stack_arrays\n",
      "    stacked = np.empty(shape, dtype=dtype)\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 108. MiB for an array with shape (5, 2843934) and data type object\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\envs\\4vector\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2168, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\envs\\4vector\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1457, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\envs\\4vector\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1348, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\envs\\4vector\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1195, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\envs\\4vector\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1085, in format_exception_as_a_whole\n",
      "    self.get_records(etb, number_of_lines_of_context, tb_offset) if etb else []\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\envs\\4vector\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1182, in get_records\n",
      "    res = list(stack_data.FrameInfo.stack_data(etb, options=options))[tb_offset:]\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\envs\\4vector\\lib\\site-packages\\stack_data\\core.py\", line 597, in stack_data\n",
      "    yield from collapse_repeated(\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\envs\\4vector\\lib\\site-packages\\stack_data\\utils.py\", line 83, in collapse_repeated\n",
      "    yield from map(mapper, original_group)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\envs\\4vector\\lib\\site-packages\\stack_data\\core.py\", line 587, in mapper\n",
      "    return cls(f, options)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\envs\\4vector\\lib\\site-packages\\stack_data\\core.py\", line 551, in __init__\n",
      "    self.executing = Source.executing(frame_or_tb)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\envs\\4vector\\lib\\site-packages\\executing\\executing.py\", line 224, in executing\n",
      "    source = cls.for_frame(frame)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\envs\\4vector\\lib\\site-packages\\executing\\executing.py\", line 143, in for_frame\n",
      "    return cls.for_filename(frame.f_code.co_filename, frame.f_globals or {}, use_cache)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\envs\\4vector\\lib\\site-packages\\executing\\executing.py\", line 172, in for_filename\n",
      "    return cls._for_filename_and_lines(filename, tuple(lines))\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\envs\\4vector\\lib\\site-packages\\executing\\executing.py\", line 183, in _for_filename_and_lines\n",
      "    result = source_cache[(filename, lines)] = cls(filename, lines)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\envs\\4vector\\lib\\site-packages\\executing\\executing.py\", line 114, in __init__\n",
      "    self.lines = [line.rstrip('\\r\\n') for line in lines]\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\envs\\4vector\\lib\\site-packages\\executing\\executing.py\", line 114, in <listcomp>\n",
      "    self.lines = [line.rstrip('\\r\\n') for line in lines]\n",
      "MemoryError\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# =====================================================\n",
    "# 1ï¸âƒ£ ë°ì´í„° ë¡œë“œ + ì‹œê°„ íŒŒìƒ\n",
    "# =====================================================\n",
    "df = pd.read_csv(\"new_flight_weather_merged.csv\")\n",
    "\n",
    "df[\"departure_datetime\"] = pd.to_datetime(df[\"departure_datetime\"])\n",
    "df[\"dep_hour\"] = df[\"departure_datetime\"].dt.hour\n",
    "df[\"dep_weekday\"] = df[\"departure_datetime\"].dt.weekday\n",
    "df[\"is_weekend\"] = df[\"dep_weekday\"].isin([5, 6]).astype(int)\n",
    "\n",
    "# =====================================================\n",
    "# 2ï¸âƒ£ ìƒíƒœ â†’ ë‹¤ì¤‘ë¶„ë¥˜ ë¼ë²¨ ìƒì„±\n",
    "# =====================================================\n",
    "# ìƒíƒœ ì»¬ëŸ¼ ê¸°ì¤€\n",
    "# ì •ìƒìš´í•­ / ì§€ì—° / íšŒí•­ / ì·¨ì†Œ\n",
    "\n",
    "label_map = {\n",
    "    \"ì •ìƒìš´í•­\": \"ë¬¸ì œì—†ìŒ\",\n",
    "    \"ì§€ì—°\": \"ì§€ì—°\",\n",
    "    \"íšŒí•­\": \"íšŒí•­\",\n",
    "    \"ì·¨ì†Œ\": \"ì·¨ì†Œ\"\n",
    "}\n",
    "\n",
    "df = df[df[\"ìƒíƒœ\"].isin(label_map.keys())].copy()\n",
    "df[\"target\"] = df[\"ìƒíƒœ\"].map(label_map)\n",
    "\n",
    "print(\"í´ë˜ìŠ¤ ë¶„í¬ (ì›ë³¸)\")\n",
    "print(df[\"target\"].value_counts())\n",
    "\n",
    "# =====================================================\n",
    "# 3ï¸âƒ£ ì»¬ëŸ¼ ì •ì˜\n",
    "# =====================================================\n",
    "num_cols = [\"ê¸°ì˜¨(Â°C)\", \"í’ì†_ms\", \"dep_hour\", \"dep_weekday\", \"is_weekend\"]\n",
    "num_cols = [c for c in num_cols if c in df.columns]\n",
    "\n",
    "cat_cols = [\"ê³µí•­ëª…\", \"ì¶œë°œì§€\", \"ë„ì°©ì§€\", \"flight_type\"]\n",
    "cat_cols = [c for c in cat_cols if c in df.columns]\n",
    "\n",
    "for c in cat_cols:\n",
    "    df[c] = df[c].astype(\"category\")\n",
    "\n",
    "X_cols = num_cols + cat_cols\n",
    "\n",
    "# =====================================================\n",
    "# 4ï¸âƒ£ Train / Test ë¶„ë¦¬ (ì‹œê°„ ê¸°ì¤€)\n",
    "# =====================================================\n",
    "df = df.sort_values(\"departure_datetime\")\n",
    "split_date = df[\"departure_datetime\"].quantile(0.8)\n",
    "\n",
    "train_df = df[df[\"departure_datetime\"] <= split_date]\n",
    "test_df  = df[df[\"departure_datetime\"] > split_date]\n",
    "\n",
    "print(\"Train:\", len(train_df), \"Test:\", len(test_df))\n",
    "\n",
    "# =====================================================\n",
    "# 5ï¸âƒ£ ğŸ”¥ ë‹¤ìš´ì‚¬ì´ì§• (Trainë§Œ)\n",
    "#    - ë¬¸ì œì—†ìŒ / ì§€ì—° â†“\n",
    "#    - íšŒí•­ / ì·¨ì†Œ ê·¸ëŒ€ë¡œ ìœ ì§€\n",
    "# =====================================================\n",
    "train_ok   = train_df[train_df[\"target\"] == \"ë¬¸ì œì—†ìŒ\"]\n",
    "train_delay = train_df[train_df[\"target\"] == \"ì§€ì—°\"]\n",
    "train_divert = train_df[train_df[\"target\"] == \"íšŒí•­\"]\n",
    "train_cancel = train_df[train_df[\"target\"] == \"ì·¨ì†Œ\"]\n",
    "\n",
    "# ê¸°ì¤€ ê°œìˆ˜ = ì§€ì—° í´ë˜ìŠ¤\n",
    "base_n = len(train_delay)\n",
    "\n",
    "train_ok_down = train_ok.sample(n=base_n, random_state=42)\n",
    "train_delay_down = train_delay.sample(n=base_n, random_state=42)\n",
    "\n",
    "train_down = pd.concat([\n",
    "    train_ok_down,\n",
    "    train_delay_down,\n",
    "    train_divert,\n",
    "    train_cancel\n",
    "]).sample(frac=1, random_state=42)\n",
    "\n",
    "print(\"\\ní´ë˜ìŠ¤ ë¶„í¬ (ë‹¤ìš´ì‚¬ì´ì§• í›„)\")\n",
    "print(train_down[\"target\"].value_counts())\n",
    "\n",
    "# =====================================================\n",
    "# 6ï¸âƒ£ X / y ë¶„ë¦¬\n",
    "# =====================================================\n",
    "X_train = train_down[X_cols]\n",
    "y_train = train_down[\"target\"]\n",
    "\n",
    "X_test  = test_df[X_cols]\n",
    "y_test  = test_df[\"target\"]\n",
    "\n",
    "# =====================================================\n",
    "# 7ï¸âƒ£ LightGBM ë‹¤ì¤‘ë¶„ë¥˜ ëª¨ë¸\n",
    "# =====================================================\n",
    "lgbm = LGBMClassifier(\n",
    "    objective=\"multiclass\",\n",
    "    num_class=4,\n",
    "\n",
    "    n_estimators=600,\n",
    "    learning_rate=0.05,\n",
    "    num_leaves=64,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "lgbm.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    categorical_feature=cat_cols\n",
    ")\n",
    "\n",
    "print(\"\\nâœ… LightGBM ë‹¤ì¤‘ë¶„ë¥˜ í•™ìŠµ ì™„ë£Œ\")\n",
    "\n",
    "# =====================================================\n",
    "# 8ï¸âƒ£ í‰ê°€\n",
    "# =====================================================\n",
    "y_pred = lgbm.predict(X_test)\n",
    "\n",
    "print(\"\\nğŸ“Š Multiclass Classification Report\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74cb79f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-22T08:36:45.148679Z",
     "start_time": "2026-01-22T08:36:45.148679Z"
    }
   },
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# âœ… í•œê¸€ í°íŠ¸ ê¹¨ì§ ë°©ì§€ ì„¤ì •\n",
    "# ===============================\n",
    "import matplotlib.pyplot as plt\n",
    "import platform\n",
    "import matplotlib.font_manager as fm\n",
    "\n",
    "system = platform.system()\n",
    "\n",
    "if system == \"Windows\":\n",
    "    # Windows (ëŒ€ë¶€ë¶„ Malgun Gothic ì‚¬ìš©)\n",
    "    plt.rcParams[\"font.family\"] = \"Malgun Gothic\"\n",
    "\n",
    "elif system == \"Darwin\":\n",
    "    # macOS\n",
    "    plt.rcParams[\"font.family\"] = \"AppleGothic\"\n",
    "\n",
    "else:\n",
    "    # Linux (Colab / ì„œë²„)\n",
    "    # ë‚˜ëˆ”ê³ ë”•ì´ ì—†ì„ ê²½ìš° ëŒ€ë¹„\n",
    "    try:\n",
    "        plt.rcParams[\"font.family\"] = \"NanumGothic\"\n",
    "    except:\n",
    "        plt.rcParams[\"font.family\"] = \"DejaVu Sans\"\n",
    "\n",
    "# ë§ˆì´ë„ˆìŠ¤ ê¸°í˜¸ ê¹¨ì§ ë°©ì§€\n",
    "plt.rcParams[\"axes.unicode_minus\"] = False\n",
    "\n",
    "print(f\"âœ… í•œê¸€ í°íŠ¸ ì„¤ì • ì™„ë£Œ ({system})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c3c959",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-22T08:36:45.150671Z",
     "start_time": "2026-01-22T08:36:45.150671Z"
    }
   },
   "outputs": [],
   "source": [
    "# =====================================================\n",
    "# 9ï¸âƒ£ (ì¶”ê°€) ì‹œê°í™”ìš© í‘œ/ê·¸ë˜í”„ ëª¨ìŒ\n",
    "#    âœ… ê¸°ì¡´ í•™ìŠµ/í‰ê°€ ì½”ë“œ(ìœ„)ëŠ” \"ê·¸ëŒ€ë¡œ\" ë‘ê³ ,\n",
    "#    âœ… ì•„ë˜ ì…€ë§Œ ì‹¤í–‰í•˜ë©´ ê²°ê³¼ë¥¼ í•œëˆˆì— ë³¼ ìˆ˜ ìˆë„ë¡ êµ¬ì„±í–ˆìŠµë‹ˆë‹¤.\n",
    "# =====================================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# A) í•„ìˆ˜ ë³€ìˆ˜ ì²´í¬ (ìœ„ ì…€ì—ì„œ ìƒì„±ë¼ ìˆì–´ì•¼ í•©ë‹ˆë‹¤)\n",
    "# -----------------------------------------------------\n",
    "required_vars = [\"lgbm\", \"X_test\", \"y_test\", \"y_pred\"]\n",
    "missing = [v for v in required_vars if v not in globals()]\n",
    "\n",
    "if missing:\n",
    "    print(\"âš ï¸ ì•„ë˜ ë³€ìˆ˜ë“¤ì´ í˜„ì¬ ë…¸íŠ¸ë¶ ì„¸ì…˜ì— ì—†ìŠµë‹ˆë‹¤:\", missing)\n",
    "    print(\"ğŸ‘‰ ìœ„ì˜ í•™ìŠµ/í‰ê°€ ì…€ì„ ë¨¼ì € ì‹¤í–‰í•œ ë’¤, ë‹¤ì‹œ ì´ ì…€ì„ ì‹¤í–‰í•˜ì„¸ìš”.\")\n",
    "else:\n",
    "    # -------------------------------------------------\n",
    "    # B) í´ë˜ìŠ¤ ìˆœì„œ(ë¼ë²¨) ê²°ì •\n",
    "    #    - í˜¼ë™í–‰ë ¬/ë§‰ëŒ€ê·¸ë˜í”„ì—ì„œ 'í•­ìƒ ê°™ì€ ìˆœì„œ'ë¡œ ë³´ê¸° ìœ„í•´ ê³ ì • ìˆœì„œ ì‚¬ìš©\n",
    "    #    - ë°ì´í„°ì— ì—†ëŠ” ë¼ë²¨ì€ ìë™ ì œê±°\n",
    "    # -------------------------------------------------\n",
    "    preferred_order = [\"ë¬¸ì œì—†ìŒ\", \"ì§€ì—°\", \"ì·¨ì†Œ\", \"íšŒí•­\"]\n",
    "    present_labels = list(pd.unique(pd.concat([\n",
    "        pd.Series(y_test, name=\"y_test\"),\n",
    "        pd.Series(y_pred, name=\"y_pred\")\n",
    "    ])))\n",
    "\n",
    "    labels = [c for c in preferred_order if c in present_labels]\n",
    "    # í˜¹ì‹œ ì˜ˆìƒ ì™¸ ë¼ë²¨ì´ ìˆì„ ê²½ìš°ë¥¼ ëŒ€ë¹„í•´, ë‚¨ì€ ë¼ë²¨ë„ ë’¤ì— ë¶™ì„\n",
    "    labels += [c for c in present_labels if c not in labels]\n",
    "\n",
    "    print(\"âœ… ì‚¬ìš© ë¼ë²¨ ìˆœì„œ:\", labels)\n",
    "\n",
    "    # -------------------------------------------------\n",
    "    # C) Classification Report â†’ í‘œ(DataFrame)ë¡œ ë³´ê¸°\n",
    "    #    - output_dict=Trueë¡œ ë°›ì•„ì„œ DataFrameìœ¼ë¡œ ë³€í™˜\n",
    "    #    - zero_division=0: ë¶„ëª¨ 0ì¸ ê²½ìš°(í¬ê·€ í´ë˜ìŠ¤) 0ìœ¼ë¡œ ì²˜ë¦¬\n",
    "    # -------------------------------------------------\n",
    "    report_dict = classification_report(\n",
    "        y_test, y_pred,\n",
    "        labels=labels,\n",
    "        output_dict=True,\n",
    "        zero_division=0\n",
    "    )\n",
    "    report_df = (\n",
    "        pd.DataFrame(report_dict)\n",
    "        .T\n",
    "        .rename(columns={\"f1-score\": \"f1\"})\n",
    "    )\n",
    "\n",
    "    # ë³´ê¸° ì¢‹ê²Œ ì†Œìˆ˜ì /ì •ë ¬\n",
    "    metric_cols = [c for c in [\"precision\", \"recall\", \"f1\", \"support\"] if c in report_df.columns]\n",
    "    report_df = report_df[metric_cols].copy()\n",
    "    report_df.loc[:, [\"precision\", \"recall\", \"f1\"]] = report_df[[\"precision\", \"recall\", \"f1\"]].round(4)\n",
    "\n",
    "    print(\"\\nğŸ“Œ Classification Report (í‘œ)\")\n",
    "    display(report_df)\n",
    "\n",
    "    # -------------------------------------------------\n",
    "    # D) í˜¼ë™í–‰ë ¬(Confusion Matrix)\n",
    "    #    1) Raw(ì ˆëŒ€ê°’)\n",
    "    #    2) Normalized(í–‰ ê¸°ì¤€ ë¹„ìœ¨: ì‹¤ì œ í´ë˜ìŠ¤ë³„ë¡œ ì–´ë””ë¡œ í˜ë €ëŠ”ì§€)\n",
    "    # -------------------------------------------------\n",
    "    cm = confusion_matrix(y_test, y_pred, labels=labels)\n",
    "\n",
    "    def plot_cm(matrix, title, normalize=False):\n",
    "        \"\"\"matplotlibë§Œìœ¼ë¡œ í˜¼ë™í–‰ë ¬ì„ ê·¸ë¦½ë‹ˆë‹¤(Seaborn ë¯¸ì‚¬ìš©).\"\"\"\n",
    "        fig, ax = plt.subplots(figsize=(7, 6))\n",
    "        im = ax.imshow(matrix, aspect=\"auto\")\n",
    "\n",
    "        ax.set_title(title)\n",
    "        ax.set_xlabel(\"Predicted (ì˜ˆì¸¡)\")\n",
    "        ax.set_ylabel(\"True (ì‹¤ì œ)\")\n",
    "\n",
    "        ax.set_xticks(range(len(labels)))\n",
    "        ax.set_yticks(range(len(labels)))\n",
    "        ax.set_xticklabels(labels, rotation=45, ha=\"right\")\n",
    "        ax.set_yticklabels(labels)\n",
    "\n",
    "        # ê° ì…€ì— ê°’ í‘œì‹œ\n",
    "        for i in range(matrix.shape[0]):\n",
    "            for j in range(matrix.shape[1]):\n",
    "                val = matrix[i, j]\n",
    "                if normalize:\n",
    "                    txt = f\"{val:.2f}\"\n",
    "                else:\n",
    "                    txt = f\"{int(val)}\"\n",
    "                ax.text(j, i, txt, ha=\"center\", va=\"center\")\n",
    "\n",
    "        plt.colorbar(im, ax=ax)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    # 1) ì ˆëŒ€ê°’ í˜¼ë™í–‰ë ¬\n",
    "    plot_cm(cm, \"Confusion Matrix (Raw Counts)\", normalize=False)\n",
    "\n",
    "    # 2) ì •ê·œí™”(í–‰ ê¸°ì¤€)\n",
    "    cm_row_sum = cm.sum(axis=1, keepdims=True)\n",
    "    cm_norm = np.divide(cm, cm_row_sum, out=np.zeros_like(cm, dtype=float), where=cm_row_sum != 0)\n",
    "    plot_cm(cm_norm, \"Confusion Matrix (Row-normalized)\", normalize=True)\n",
    "\n",
    "    # -------------------------------------------------\n",
    "    # E) ì‹¤ì œ ë¶„í¬ vs ì˜ˆì¸¡ ë¶„í¬ (í´ë˜ìŠ¤ ë¶ˆê· í˜•/ì ë¦¼ í™•ì¸)\n",
    "    # -------------------------------------------------\n",
    "    true_counts = pd.Series(y_test).value_counts().reindex(labels, fill_value=0)\n",
    "    pred_counts = pd.Series(y_pred).value_counts().reindex(labels, fill_value=0)\n",
    "\n",
    "    dist_df = pd.DataFrame({\n",
    "        \"true_count\": true_counts,\n",
    "        \"pred_count\": pred_counts\n",
    "    })\n",
    "\n",
    "    print(\"\\nğŸ“Œ ì‹¤ì œ/ì˜ˆì¸¡ ë¶„í¬ (í‘œ)\")\n",
    "    display(dist_df)\n",
    "\n",
    "    # ë§‰ëŒ€ê·¸ë˜í”„(ê°™ì€ ì¶•ì—ì„œ ë¹„êµ)\n",
    "    fig, ax = plt.subplots(figsize=(8, 4))\n",
    "    x = np.arange(len(labels))\n",
    "    width = 0.35\n",
    "\n",
    "    ax.bar(x - width/2, dist_df[\"true_count\"], width, label=\"True\")\n",
    "    ax.bar(x + width/2, dist_df[\"pred_count\"], width, label=\"Pred\")\n",
    "\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(labels, rotation=0)\n",
    "    ax.set_title(\"Class Distribution: True vs Pred\")\n",
    "    ax.set_ylabel(\"Count\")\n",
    "    ax.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # -------------------------------------------------\n",
    "    # F) í´ë˜ìŠ¤ë³„ F1(ë§‰ëŒ€ê·¸ë˜í”„)\n",
    "    #    - ì–´ë–¤ í´ë˜ìŠ¤ì—ì„œ ì„±ëŠ¥ì´ ë¬´ë„ˆì§€ëŠ”ì§€ ë¹ ë¥´ê²Œ í™•ì¸\n",
    "    # -------------------------------------------------\n",
    "    class_rows = [c for c in labels if c in report_df.index]\n",
    "    f1_vals = report_df.loc[class_rows, \"f1\"].values\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 4))\n",
    "    ax.bar(class_rows, f1_vals)\n",
    "    ax.set_ylim(0, 1.0)\n",
    "    ax.set_title(\"F1-score by Class\")\n",
    "    ax.set_ylabel(\"F1\")\n",
    "    plt.xticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # -------------------------------------------------\n",
    "    # G) Feature Importance (LightGBM)\n",
    "    #    - ëª¨ë¸ì´ ì–´ë–¤ í”¼ì²˜ë¥¼ ì¤‘ìš”í•˜ê²Œ ë³´ëŠ”ì§€ í™•ì¸\n",
    "    #    - ìƒìœ„ TOP 20ë§Œ ì¶œë ¥/ì‹œê°í™”\n",
    "    # -------------------------------------------------\n",
    "    if hasattr(lgbm, \"feature_importances_\"):\n",
    "        # feature ì´ë¦„ í™•ë³´ (ìš°ì„ ìˆœìœ„: X_train.columns â†’ X_cols â†’ None)\n",
    "        if \"X_train\" in globals() and hasattr(X_train, \"columns\"):\n",
    "            feature_names = list(X_train.columns)\n",
    "        elif \"X_cols\" in globals():\n",
    "            feature_names = list(X_cols)\n",
    "        else:\n",
    "            feature_names = [f\"f{i}\" for i in range(len(lgbm.feature_importances_))]\n",
    "\n",
    "        fi = pd.DataFrame({\n",
    "            \"feature\": feature_names,\n",
    "            \"importance\": lgbm.feature_importances_\n",
    "        }).sort_values(\"importance\", ascending=False)\n",
    "\n",
    "        print(\"\\nğŸ“Œ Feature Importance TOP 20 (í‘œ)\")\n",
    "        display(fi.head(20))\n",
    "\n",
    "        topk = fi.head(20).iloc[::-1]  # ê·¸ë˜í”„ëŠ” ìœ„â†’ì•„ë˜ ì½ê¸° í¸í•˜ê²Œ ì—­ìˆœ\n",
    "        fig, ax = plt.subplots(figsize=(8, 6))\n",
    "        ax.barh(topk[\"feature\"], topk[\"importance\"])\n",
    "        ax.set_title(\"Feature Importance (Top 20)\")\n",
    "        ax.set_xlabel(\"Importance\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"\\nâ„¹ï¸ lgbm.feature_importances_ ë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ Feature ImportanceëŠ” ê±´ë„ˆëœë‹ˆë‹¤.\")\n",
    "\n",
    "    # -------------------------------------------------\n",
    "    # H) ì˜ˆì¸¡ í™•ë¥  ê¸°ë°˜ \"ìì‹ ê°\" ë¶„í¬ (ì„ íƒ)\n",
    "    #    - multiclassì—ì„œëŠ” predict_probaë¡œ ê° í´ë˜ìŠ¤ í™•ë¥ ì„ ì–»ì„ ìˆ˜ ìˆìŒ\n",
    "    #    - max_probaê°€ ë‚®ìœ¼ë©´ ëª¨ë¸ì´ í—·ê°ˆë¦¬ëŠ” ìƒ˜í”Œì´ ë§ë‹¤ëŠ” ëœ»\n",
    "    # -------------------------------------------------\n",
    "    try:\n",
    "        proba = lgbm.predict_proba(X_test)\n",
    "\n",
    "        # probaê°€ (n_samples, n_classes) í˜•íƒœë¼ê³  ê°€ì •\n",
    "        max_proba = np.max(proba, axis=1)\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(8, 4))\n",
    "        ax.hist(max_proba, bins=30)\n",
    "        ax.set_title(\"Prediction Confidence (max class probability)\")\n",
    "        ax.set_xlabel(\"max_proba\")\n",
    "        ax.set_ylabel(\"Frequency\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        # í—·ê°ˆë¦¬ëŠ” ìƒ˜í”Œ(ìì‹ ê° ë‚®ì€ ìˆœ) TOP 10ì„ í‘œë¡œ í™•ì¸\n",
    "        # - ìš´ì˜ ê´€ì ì—ì„œ 'ì‚¬ëŒì´ ê²€í† í•  í›„ë³´'ë¥¼ ë½‘ì„ ë•Œ ìœ ìš©\n",
    "        hard_idx = np.argsort(max_proba)[:10]\n",
    "        hard_df = pd.DataFrame({\n",
    "            \"index\": hard_idx,\n",
    "            \"true\": np.array(y_test)[hard_idx],\n",
    "            \"pred\": np.array(y_pred)[hard_idx],\n",
    "            \"max_proba\": max_proba[hard_idx]\n",
    "        }).sort_values(\"max_proba\")\n",
    "\n",
    "        print(\"\\nğŸ“Œ ëª¨ë¸ì´ ê°€ì¥ í—·ê°ˆë¦° ìƒ˜í”Œ TOP 10 (í‘œ)\")\n",
    "        display(hard_df)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"\\nâ„¹ï¸ predict_proba ê¸°ë°˜ ì‹œê°í™”ëŠ” í˜„ì¬ í™˜ê²½/ëª¨ë¸ ì„¤ì •ì—ì„œ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.\")\n",
    "        print(\"ì—ëŸ¬:\", repr(e))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "4vector(ipykernel)",
   "language": "python",
   "name": "4vector"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
