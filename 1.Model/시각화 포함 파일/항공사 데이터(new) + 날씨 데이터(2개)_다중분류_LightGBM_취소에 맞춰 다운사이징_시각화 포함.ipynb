{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5063b61",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-22T08:36:49.022567Z",
     "start_time": "2026-01-22T08:35:58.573179Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_10136\\3103664467.py:9: DtypeWarning: Columns (29,50) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"new_flight_weather_merged.csv\")\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 21.7 MiB for an array with shape (1, 2843934) and data type object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 9\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m classification_report\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# =====================================================\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# 1ï¸âƒ£ ë°ì´í„° ë¡œë“œ + ì‹œê°„ íŒŒìƒ\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# =====================================================\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnew_flight_weather_merged.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeparture_datetime\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeparture_datetime\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     12\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdep_hour\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeparture_datetime\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mhour\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\4vector\\lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\4vector\\lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\4vector\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m    947\u001b[0m )\n\u001b[0;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\4vector\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[0;32m    610\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[1;32m--> 611\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\4vector\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1795\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1792\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1793\u001b[0m         new_rows \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(index)\n\u001b[1;32m-> 1795\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcol_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1797\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_currow \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m new_rows\n\u001b[0;32m   1799\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msqueeze \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(df\u001b[38;5;241m.\u001b[39mcolumns) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\4vector\\lib\\site-packages\\pandas\\core\\frame.py:664\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    658\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[0;32m    659\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[0;32m    660\u001b[0m     )\n\u001b[0;32m    662\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    663\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 664\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    665\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[0;32m    666\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmrecords\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmrecords\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\4vector\\lib\\site-packages\\pandas\\core\\internals\\construction.py:493\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    489\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    490\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[0;32m    491\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[1;32m--> 493\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\4vector\\lib\\site-packages\\pandas\\core\\internals\\construction.py:154\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    151\u001b[0m axes \u001b[38;5;241m=\u001b[39m [columns, index]\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblock\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 154\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcreate_block_manager_from_column_arrays\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconsolidate\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m typ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ArrayManager(arrays, [index, columns])\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\4vector\\lib\\site-packages\\pandas\\core\\internals\\managers.py:2199\u001b[0m, in \u001b[0;36mcreate_block_manager_from_column_arrays\u001b[1;34m(arrays, axes, consolidate)\u001b[0m\n\u001b[0;32m   2182\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcreate_block_manager_from_column_arrays\u001b[39m(\n\u001b[0;32m   2183\u001b[0m     arrays: \u001b[38;5;28mlist\u001b[39m[ArrayLike],\n\u001b[0;32m   2184\u001b[0m     axes: \u001b[38;5;28mlist\u001b[39m[Index],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2195\u001b[0m     \u001b[38;5;66;03m# These last three are sufficient to allow us to safely pass\u001b[39;00m\n\u001b[0;32m   2196\u001b[0m     \u001b[38;5;66;03m#  verify_integrity=False below.\u001b[39;00m\n\u001b[0;32m   2198\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 2199\u001b[0m         blocks \u001b[38;5;241m=\u001b[39m \u001b[43m_form_blocks\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2200\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m BlockManager(blocks, axes, verify_integrity\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   2201\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\4vector\\lib\\site-packages\\pandas\\core\\internals\\managers.py:2273\u001b[0m, in \u001b[0;36m_form_blocks\u001b[1;34m(arrays, consolidate)\u001b[0m\n\u001b[0;32m   2270\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(dtype\u001b[38;5;241m.\u001b[39mtype, (\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mbytes\u001b[39m)):\n\u001b[0;32m   2271\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdtype(\u001b[38;5;28mobject\u001b[39m)\n\u001b[1;32m-> 2273\u001b[0m values, placement \u001b[38;5;241m=\u001b[39m \u001b[43m_stack_arrays\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtup_block\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2274\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_dtlike:\n\u001b[0;32m   2275\u001b[0m     values \u001b[38;5;241m=\u001b[39m ensure_wrapped_if_datetimelike(values)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\4vector\\lib\\site-packages\\pandas\\core\\internals\\managers.py:2312\u001b[0m, in \u001b[0;36m_stack_arrays\u001b[1;34m(tuples, dtype)\u001b[0m\n\u001b[0;32m   2309\u001b[0m first \u001b[38;5;241m=\u001b[39m arrays[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   2310\u001b[0m shape \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mlen\u001b[39m(arrays),) \u001b[38;5;241m+\u001b[39m first\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m-> 2312\u001b[0m stacked \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mempty\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2313\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, arr \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(arrays):\n\u001b[0;32m   2314\u001b[0m     stacked[i] \u001b[38;5;241m=\u001b[39m arr\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 21.7 MiB for an array with shape (1, 2843934) and data type object"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# =====================================================\n",
    "# 1ï¸âƒ£ ë°ì´í„° ë¡œë“œ + ì‹œê°„ íŒŒìƒ\n",
    "# =====================================================\n",
    "df = pd.read_csv(\"new_flight_weather_merged.csv\")\n",
    "\n",
    "df[\"departure_datetime\"] = pd.to_datetime(df[\"departure_datetime\"])\n",
    "df[\"dep_hour\"] = df[\"departure_datetime\"].dt.hour\n",
    "df[\"dep_weekday\"] = df[\"departure_datetime\"].dt.weekday\n",
    "df[\"is_weekend\"] = df[\"dep_weekday\"].isin([5, 6]).astype(int)\n",
    "\n",
    "# =====================================================\n",
    "# 2ï¸âƒ£ ìƒíƒœ â†’ ë‹¤ì¤‘ë¶„ë¥˜ ë¼ë²¨\n",
    "# =====================================================\n",
    "label_map = {\n",
    "    \"ì •ìƒìš´í•­\": \"ë¬¸ì œì—†ìŒ\",\n",
    "    \"ì§€ì—°\": \"ì§€ì—°\",\n",
    "    \"íšŒí•­\": \"íšŒí•­\",\n",
    "    \"ì·¨ì†Œ\": \"ì·¨ì†Œ\"\n",
    "}\n",
    "\n",
    "df = df[df[\"ìƒíƒœ\"].isin(label_map.keys())].copy()\n",
    "df[\"target\"] = df[\"ìƒíƒœ\"].map(label_map)\n",
    "\n",
    "print(\"ğŸ“Š ì›ë³¸ í´ë˜ìŠ¤ ë¶„í¬\")\n",
    "print(df[\"target\"].value_counts())\n",
    "\n",
    "# =====================================================\n",
    "# 3ï¸âƒ£ ì»¬ëŸ¼ ì •ì˜\n",
    "# =====================================================\n",
    "num_cols = [\"ê¸°ì˜¨(Â°C)\", \"í’ì†_ms\", \"dep_hour\", \"dep_weekday\", \"is_weekend\"]\n",
    "num_cols = [c for c in num_cols if c in df.columns]\n",
    "\n",
    "cat_cols = [\"ê³µí•­ëª…\", \"ì¶œë°œì§€\", \"ë„ì°©ì§€\", \"flight_type\"]\n",
    "cat_cols = [c for c in cat_cols if c in df.columns]\n",
    "\n",
    "for c in cat_cols:\n",
    "    df[c] = df[c].astype(\"category\")\n",
    "\n",
    "X_cols = num_cols + cat_cols\n",
    "\n",
    "# =====================================================\n",
    "# 4ï¸âƒ£ Train / Test ë¶„ë¦¬ (ì‹œê°„ ê¸°ì¤€)\n",
    "# =====================================================\n",
    "df = df.sort_values(\"departure_datetime\")\n",
    "split_date = df[\"departure_datetime\"].quantile(0.8)\n",
    "\n",
    "train_df = df[df[\"departure_datetime\"] <= split_date]\n",
    "test_df  = df[df[\"departure_datetime\"] > split_date]\n",
    "\n",
    "print(\"\\nTrain:\", len(train_df), \"Test:\", len(test_df))\n",
    "\n",
    "# =====================================================\n",
    "# 5ï¸âƒ£ ğŸ”¥ ì·¨ì†Œ ê¸°ì¤€ ë‹¤ìš´ì‚¬ì´ì§• (âš ï¸ ì‹¤í—˜ìš©)\n",
    "# =====================================================\n",
    "train_ok     = train_df[train_df[\"target\"] == \"ë¬¸ì œì—†ìŒ\"]\n",
    "train_delay  = train_df[train_df[\"target\"] == \"ì§€ì—°\"]\n",
    "train_divert = train_df[train_df[\"target\"] == \"íšŒí•­\"]\n",
    "train_cancel = train_df[train_df[\"target\"] == \"ì·¨ì†Œ\"]\n",
    "\n",
    "base_n = len(train_cancel)  # ğŸ”¥ ì·¨ì†Œ ê¸°ì¤€\n",
    "\n",
    "print(\"\\nê¸°ì¤€ ìƒ˜í”Œ ìˆ˜ (ì·¨ì†Œ):\", base_n)\n",
    "\n",
    "train_ok_down = train_ok.sample(n=base_n, random_state=42)\n",
    "train_delay_down = train_delay.sample(n=base_n, random_state=42)\n",
    "\n",
    "# íšŒí•­ì€ ë¶€ì¡±í•˜ë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš©\n",
    "train_divert_down = train_divert if len(train_divert) <= base_n else \\\n",
    "    train_divert.sample(n=base_n, random_state=42)\n",
    "\n",
    "train_down = pd.concat([\n",
    "    train_ok_down,\n",
    "    train_delay_down,\n",
    "    train_divert_down,\n",
    "    train_cancel\n",
    "]).sample(frac=1, random_state=42)\n",
    "\n",
    "print(\"\\nğŸ“Š ë‹¤ìš´ì‚¬ì´ì§• í›„ Train ë¶„í¬\")\n",
    "print(train_down[\"target\"].value_counts())\n",
    "\n",
    "# =====================================================\n",
    "# 6ï¸âƒ£ X / y ë¶„ë¦¬\n",
    "# =====================================================\n",
    "X_train = train_down[X_cols]\n",
    "y_train = train_down[\"target\"]\n",
    "\n",
    "X_test  = test_df[X_cols]\n",
    "y_test  = test_df[\"target\"]\n",
    "\n",
    "# =====================================================\n",
    "# 7ï¸âƒ£ LightGBM ë‹¤ì¤‘ë¶„ë¥˜\n",
    "# =====================================================\n",
    "lgbm = LGBMClassifier(\n",
    "    objective=\"multiclass\",\n",
    "    num_class=4,\n",
    "    n_estimators=500,\n",
    "    learning_rate=0.05,\n",
    "    num_leaves=64,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "lgbm.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    categorical_feature=cat_cols\n",
    ")\n",
    "\n",
    "print(\"\\nâœ… LightGBM (ì·¨ì†Œ ê¸°ì¤€ ë‹¤ìš´ì‚¬ì´ì§•) í•™ìŠµ ì™„ë£Œ\")\n",
    "\n",
    "# =====================================================\n",
    "# 8ï¸âƒ£ í‰ê°€\n",
    "# =====================================================\n",
    "y_pred = lgbm.predict(X_test)\n",
    "\n",
    "print(\"\\nğŸ“Š Classification Report (ì‹¤í—˜ìš©)\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27426611",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-22T08:36:49.025568Z",
     "start_time": "2026-01-22T08:36:49.025568Z"
    }
   },
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# âœ… í•œê¸€ í°íŠ¸ ê¹¨ì§ ë°©ì§€ ì„¤ì •\n",
    "# ===============================\n",
    "import matplotlib.pyplot as plt\n",
    "import platform\n",
    "import matplotlib.font_manager as fm\n",
    "\n",
    "system = platform.system()\n",
    "\n",
    "if system == \"Windows\":\n",
    "    # Windows (ëŒ€ë¶€ë¶„ Malgun Gothic ì‚¬ìš©)\n",
    "    plt.rcParams[\"font.family\"] = \"Malgun Gothic\"\n",
    "\n",
    "elif system == \"Darwin\":\n",
    "    # macOS\n",
    "    plt.rcParams[\"font.family\"] = \"AppleGothic\"\n",
    "\n",
    "else:\n",
    "    # Linux (Colab / ì„œë²„)\n",
    "    # ë‚˜ëˆ”ê³ ë”•ì´ ì—†ì„ ê²½ìš° ëŒ€ë¹„\n",
    "    try:\n",
    "        plt.rcParams[\"font.family\"] = \"NanumGothic\"\n",
    "    except:\n",
    "        plt.rcParams[\"font.family\"] = \"DejaVu Sans\"\n",
    "\n",
    "# ë§ˆì´ë„ˆìŠ¤ ê¸°í˜¸ ê¹¨ì§ ë°©ì§€\n",
    "plt.rcParams[\"axes.unicode_minus\"] = False\n",
    "\n",
    "print(f\"âœ… í•œê¸€ í°íŠ¸ ì„¤ì • ì™„ë£Œ ({system})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a58223b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-22T08:36:49.026563Z",
     "start_time": "2026-01-22T08:36:49.026563Z"
    }
   },
   "outputs": [],
   "source": [
    "# =====================================================\n",
    "# 9ï¸âƒ£ (ì¶”ê°€) ì‹œê°í™”ìš© í‘œ/ê·¸ë˜í”„ ëª¨ìŒ\n",
    "#    âœ… ê¸°ì¡´ í•™ìŠµ/í‰ê°€ ì½”ë“œ(ìœ„)ëŠ” \"ê·¸ëŒ€ë¡œ\" ë‘ê³ ,\n",
    "#    âœ… ì•„ë˜ ì…€ë§Œ ì‹¤í–‰í•˜ë©´ ê²°ê³¼ë¥¼ í•œëˆˆì— ë³¼ ìˆ˜ ìˆë„ë¡ êµ¬ì„±í–ˆìŠµë‹ˆë‹¤.\n",
    "# =====================================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# A) í•„ìˆ˜ ë³€ìˆ˜ ì²´í¬ (ìœ„ ì…€ì—ì„œ ìƒì„±ë¼ ìˆì–´ì•¼ í•©ë‹ˆë‹¤)\n",
    "# -----------------------------------------------------\n",
    "required_vars = [\"lgbm\", \"X_test\", \"y_test\", \"y_pred\"]\n",
    "missing = [v for v in required_vars if v not in globals()]\n",
    "\n",
    "if missing:\n",
    "    print(\"âš ï¸ ì•„ë˜ ë³€ìˆ˜ë“¤ì´ í˜„ì¬ ë…¸íŠ¸ë¶ ì„¸ì…˜ì— ì—†ìŠµë‹ˆë‹¤:\", missing)\n",
    "    print(\"ğŸ‘‰ ìœ„ì˜ í•™ìŠµ/í‰ê°€ ì…€ì„ ë¨¼ì € ì‹¤í–‰í•œ ë’¤, ë‹¤ì‹œ ì´ ì…€ì„ ì‹¤í–‰í•˜ì„¸ìš”.\")\n",
    "else:\n",
    "    # -------------------------------------------------\n",
    "    # B) í´ë˜ìŠ¤ ìˆœì„œ(ë¼ë²¨) ê²°ì •\n",
    "    #    - í˜¼ë™í–‰ë ¬/ë§‰ëŒ€ê·¸ë˜í”„ì—ì„œ 'í•­ìƒ ê°™ì€ ìˆœì„œ'ë¡œ ë³´ê¸° ìœ„í•´ ê³ ì • ìˆœì„œ ì‚¬ìš©\n",
    "    #    - ë°ì´í„°ì— ì—†ëŠ” ë¼ë²¨ì€ ìë™ ì œê±°\n",
    "    # -------------------------------------------------\n",
    "    preferred_order = [\"ë¬¸ì œì—†ìŒ\", \"ì§€ì—°\", \"ì·¨ì†Œ\", \"íšŒí•­\"]\n",
    "    present_labels = list(pd.unique(pd.concat([\n",
    "        pd.Series(y_test, name=\"y_test\"),\n",
    "        pd.Series(y_pred, name=\"y_pred\")\n",
    "    ])))\n",
    "\n",
    "    labels = [c for c in preferred_order if c in present_labels]\n",
    "    # í˜¹ì‹œ ì˜ˆìƒ ì™¸ ë¼ë²¨ì´ ìˆì„ ê²½ìš°ë¥¼ ëŒ€ë¹„í•´, ë‚¨ì€ ë¼ë²¨ë„ ë’¤ì— ë¶™ì„\n",
    "    labels += [c for c in present_labels if c not in labels]\n",
    "\n",
    "    print(\"âœ… ì‚¬ìš© ë¼ë²¨ ìˆœì„œ:\", labels)\n",
    "\n",
    "    # -------------------------------------------------\n",
    "    # C) Classification Report â†’ í‘œ(DataFrame)ë¡œ ë³´ê¸°\n",
    "    #    - output_dict=Trueë¡œ ë°›ì•„ì„œ DataFrameìœ¼ë¡œ ë³€í™˜\n",
    "    #    - zero_division=0: ë¶„ëª¨ 0ì¸ ê²½ìš°(í¬ê·€ í´ë˜ìŠ¤) 0ìœ¼ë¡œ ì²˜ë¦¬\n",
    "    # -------------------------------------------------\n",
    "    report_dict = classification_report(\n",
    "        y_test, y_pred,\n",
    "        labels=labels,\n",
    "        output_dict=True,\n",
    "        zero_division=0\n",
    "    )\n",
    "    report_df = (\n",
    "        pd.DataFrame(report_dict)\n",
    "        .T\n",
    "        .rename(columns={\"f1-score\": \"f1\"})\n",
    "    )\n",
    "\n",
    "    # ë³´ê¸° ì¢‹ê²Œ ì†Œìˆ˜ì /ì •ë ¬\n",
    "    metric_cols = [c for c in [\"precision\", \"recall\", \"f1\", \"support\"] if c in report_df.columns]\n",
    "    report_df = report_df[metric_cols].copy()\n",
    "    report_df.loc[:, [\"precision\", \"recall\", \"f1\"]] = report_df[[\"precision\", \"recall\", \"f1\"]].round(4)\n",
    "\n",
    "    print(\"\\nğŸ“Œ Classification Report (í‘œ)\")\n",
    "    display(report_df)\n",
    "\n",
    "    # -------------------------------------------------\n",
    "    # D) í˜¼ë™í–‰ë ¬(Confusion Matrix)\n",
    "    #    1) Raw(ì ˆëŒ€ê°’)\n",
    "    #    2) Normalized(í–‰ ê¸°ì¤€ ë¹„ìœ¨: ì‹¤ì œ í´ë˜ìŠ¤ë³„ë¡œ ì–´ë””ë¡œ í˜ë €ëŠ”ì§€)\n",
    "    # -------------------------------------------------\n",
    "    cm = confusion_matrix(y_test, y_pred, labels=labels)\n",
    "\n",
    "    def plot_cm(matrix, title, normalize=False):\n",
    "        \"\"\"matplotlibë§Œìœ¼ë¡œ í˜¼ë™í–‰ë ¬ì„ ê·¸ë¦½ë‹ˆë‹¤(Seaborn ë¯¸ì‚¬ìš©).\"\"\"\n",
    "        fig, ax = plt.subplots(figsize=(7, 6))\n",
    "        im = ax.imshow(matrix, aspect=\"auto\")\n",
    "\n",
    "        ax.set_title(title)\n",
    "        ax.set_xlabel(\"Predicted (ì˜ˆì¸¡)\")\n",
    "        ax.set_ylabel(\"True (ì‹¤ì œ)\")\n",
    "\n",
    "        ax.set_xticks(range(len(labels)))\n",
    "        ax.set_yticks(range(len(labels)))\n",
    "        ax.set_xticklabels(labels, rotation=45, ha=\"right\")\n",
    "        ax.set_yticklabels(labels)\n",
    "\n",
    "        # ê° ì…€ì— ê°’ í‘œì‹œ\n",
    "        for i in range(matrix.shape[0]):\n",
    "            for j in range(matrix.shape[1]):\n",
    "                val = matrix[i, j]\n",
    "                if normalize:\n",
    "                    txt = f\"{val:.2f}\"\n",
    "                else:\n",
    "                    txt = f\"{int(val)}\"\n",
    "                ax.text(j, i, txt, ha=\"center\", va=\"center\")\n",
    "\n",
    "        plt.colorbar(im, ax=ax)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    # 1) ì ˆëŒ€ê°’ í˜¼ë™í–‰ë ¬\n",
    "    plot_cm(cm, \"Confusion Matrix (Raw Counts)\", normalize=False)\n",
    "\n",
    "    # 2) ì •ê·œí™”(í–‰ ê¸°ì¤€)\n",
    "    cm_row_sum = cm.sum(axis=1, keepdims=True)\n",
    "    cm_norm = np.divide(cm, cm_row_sum, out=np.zeros_like(cm, dtype=float), where=cm_row_sum != 0)\n",
    "    plot_cm(cm_norm, \"Confusion Matrix (Row-normalized)\", normalize=True)\n",
    "\n",
    "    # -------------------------------------------------\n",
    "    # E) ì‹¤ì œ ë¶„í¬ vs ì˜ˆì¸¡ ë¶„í¬ (í´ë˜ìŠ¤ ë¶ˆê· í˜•/ì ë¦¼ í™•ì¸)\n",
    "    # -------------------------------------------------\n",
    "    true_counts = pd.Series(y_test).value_counts().reindex(labels, fill_value=0)\n",
    "    pred_counts = pd.Series(y_pred).value_counts().reindex(labels, fill_value=0)\n",
    "\n",
    "    dist_df = pd.DataFrame({\n",
    "        \"true_count\": true_counts,\n",
    "        \"pred_count\": pred_counts\n",
    "    })\n",
    "\n",
    "    print(\"\\nğŸ“Œ ì‹¤ì œ/ì˜ˆì¸¡ ë¶„í¬ (í‘œ)\")\n",
    "    display(dist_df)\n",
    "\n",
    "    # ë§‰ëŒ€ê·¸ë˜í”„(ê°™ì€ ì¶•ì—ì„œ ë¹„êµ)\n",
    "    fig, ax = plt.subplots(figsize=(8, 4))\n",
    "    x = np.arange(len(labels))\n",
    "    width = 0.35\n",
    "\n",
    "    ax.bar(x - width/2, dist_df[\"true_count\"], width, label=\"True\")\n",
    "    ax.bar(x + width/2, dist_df[\"pred_count\"], width, label=\"Pred\")\n",
    "\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(labels, rotation=0)\n",
    "    ax.set_title(\"Class Distribution: True vs Pred\")\n",
    "    ax.set_ylabel(\"Count\")\n",
    "    ax.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # -------------------------------------------------\n",
    "    # F) í´ë˜ìŠ¤ë³„ F1(ë§‰ëŒ€ê·¸ë˜í”„)\n",
    "    #    - ì–´ë–¤ í´ë˜ìŠ¤ì—ì„œ ì„±ëŠ¥ì´ ë¬´ë„ˆì§€ëŠ”ì§€ ë¹ ë¥´ê²Œ í™•ì¸\n",
    "    # -------------------------------------------------\n",
    "    class_rows = [c for c in labels if c in report_df.index]\n",
    "    f1_vals = report_df.loc[class_rows, \"f1\"].values\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 4))\n",
    "    ax.bar(class_rows, f1_vals)\n",
    "    ax.set_ylim(0, 1.0)\n",
    "    ax.set_title(\"F1-score by Class\")\n",
    "    ax.set_ylabel(\"F1\")\n",
    "    plt.xticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # -------------------------------------------------\n",
    "    # G) Feature Importance (LightGBM)\n",
    "    #    - ëª¨ë¸ì´ ì–´ë–¤ í”¼ì²˜ë¥¼ ì¤‘ìš”í•˜ê²Œ ë³´ëŠ”ì§€ í™•ì¸\n",
    "    #    - ìƒìœ„ TOP 20ë§Œ ì¶œë ¥/ì‹œê°í™”\n",
    "    # -------------------------------------------------\n",
    "    if hasattr(lgbm, \"feature_importances_\"):\n",
    "        # feature ì´ë¦„ í™•ë³´ (ìš°ì„ ìˆœìœ„: X_train.columns â†’ X_cols â†’ None)\n",
    "        if \"X_train\" in globals() and hasattr(X_train, \"columns\"):\n",
    "            feature_names = list(X_train.columns)\n",
    "        elif \"X_cols\" in globals():\n",
    "            feature_names = list(X_cols)\n",
    "        else:\n",
    "            feature_names = [f\"f{i}\" for i in range(len(lgbm.feature_importances_))]\n",
    "\n",
    "        fi = pd.DataFrame({\n",
    "            \"feature\": feature_names,\n",
    "            \"importance\": lgbm.feature_importances_\n",
    "        }).sort_values(\"importance\", ascending=False)\n",
    "\n",
    "        print(\"\\nğŸ“Œ Feature Importance TOP 20 (í‘œ)\")\n",
    "        display(fi.head(20))\n",
    "\n",
    "        topk = fi.head(20).iloc[::-1]  # ê·¸ë˜í”„ëŠ” ìœ„â†’ì•„ë˜ ì½ê¸° í¸í•˜ê²Œ ì—­ìˆœ\n",
    "        fig, ax = plt.subplots(figsize=(8, 6))\n",
    "        ax.barh(topk[\"feature\"], topk[\"importance\"])\n",
    "        ax.set_title(\"Feature Importance (Top 20)\")\n",
    "        ax.set_xlabel(\"Importance\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"\\nâ„¹ï¸ lgbm.feature_importances_ ë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ Feature ImportanceëŠ” ê±´ë„ˆëœë‹ˆë‹¤.\")\n",
    "\n",
    "    # -------------------------------------------------\n",
    "    # H) ì˜ˆì¸¡ í™•ë¥  ê¸°ë°˜ \"ìì‹ ê°\" ë¶„í¬ (ì„ íƒ)\n",
    "    #    - multiclassì—ì„œëŠ” predict_probaë¡œ ê° í´ë˜ìŠ¤ í™•ë¥ ì„ ì–»ì„ ìˆ˜ ìˆìŒ\n",
    "    #    - max_probaê°€ ë‚®ìœ¼ë©´ ëª¨ë¸ì´ í—·ê°ˆë¦¬ëŠ” ìƒ˜í”Œì´ ë§ë‹¤ëŠ” ëœ»\n",
    "    # -------------------------------------------------\n",
    "    try:\n",
    "        proba = lgbm.predict_proba(X_test)\n",
    "\n",
    "        # probaê°€ (n_samples, n_classes) í˜•íƒœë¼ê³  ê°€ì •\n",
    "        max_proba = np.max(proba, axis=1)\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(8, 4))\n",
    "        ax.hist(max_proba, bins=30)\n",
    "        ax.set_title(\"Prediction Confidence (max class probability)\")\n",
    "        ax.set_xlabel(\"max_proba\")\n",
    "        ax.set_ylabel(\"Frequency\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        # í—·ê°ˆë¦¬ëŠ” ìƒ˜í”Œ(ìì‹ ê° ë‚®ì€ ìˆœ) TOP 10ì„ í‘œë¡œ í™•ì¸\n",
    "        # - ìš´ì˜ ê´€ì ì—ì„œ 'ì‚¬ëŒì´ ê²€í† í•  í›„ë³´'ë¥¼ ë½‘ì„ ë•Œ ìœ ìš©\n",
    "        hard_idx = np.argsort(max_proba)[:10]\n",
    "        hard_df = pd.DataFrame({\n",
    "            \"index\": hard_idx,\n",
    "            \"true\": np.array(y_test)[hard_idx],\n",
    "            \"pred\": np.array(y_pred)[hard_idx],\n",
    "            \"max_proba\": max_proba[hard_idx]\n",
    "        }).sort_values(\"max_proba\")\n",
    "\n",
    "        print(\"\\nğŸ“Œ ëª¨ë¸ì´ ê°€ì¥ í—·ê°ˆë¦° ìƒ˜í”Œ TOP 10 (í‘œ)\")\n",
    "        display(hard_df)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"\\nâ„¹ï¸ predict_proba ê¸°ë°˜ ì‹œê°í™”ëŠ” í˜„ì¬ í™˜ê²½/ëª¨ë¸ ì„¤ì •ì—ì„œ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.\")\n",
    "        print(\"ì—ëŸ¬:\", repr(e))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "4vector(ipykernel)",
   "language": "python",
   "name": "4vector"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
