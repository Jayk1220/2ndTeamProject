{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc7d6299",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-21T08:28:15.032570Z",
     "start_time": "2026-01-21T08:27:57.371718Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_12984\\4191327705.py:13: DtypeWarning: Columns (28,49) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"new_flight_weather_merged.csv\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ CSV Î°úÎìú: 2843934\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    roc_auc_score,\n",
    "    average_precision_score\n",
    ")\n",
    "\n",
    "# =========================\n",
    "# Îç∞Ïù¥ÌÑ∞ Î°úÎìú\n",
    "# =========================\n",
    "df = pd.read_csv(\"new_flight_weather_merged.csv\")\n",
    "print(\"‚úÖ CSV Î°úÎìú:\", len(df))\n",
    "\n",
    "# =========================\n",
    "# ÏãúÍ∞Ñ ÌååÏÉù Î≥ÄÏàò\n",
    "# =========================\n",
    "df[\"departure_datetime\"] = pd.to_datetime(df[\"departure_datetime\"])\n",
    "\n",
    "df[\"dep_hour\"] = df[\"departure_datetime\"].dt.hour\n",
    "df[\"dep_weekday\"] = df[\"departure_datetime\"].dt.weekday\n",
    "df[\"is_weekend\"] = df[\"dep_weekday\"].isin([5, 6]).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c30de288",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-21T08:28:15.047627Z",
     "start_time": "2026-01-21T08:28:15.033618Z"
    }
   },
   "outputs": [],
   "source": [
    "# üî¢ ÏàòÏπòÌòï\n",
    "num_cols = [\n",
    "    \"Í∏∞Ïò®(¬∞C)\",\n",
    "    \"ÌíçÏÜç_ms\",\n",
    "    \"dep_hour\",\n",
    "    \"dep_weekday\",\n",
    "    \"is_weekend\"\n",
    "]\n",
    "num_cols = [c for c in num_cols if c in df.columns]\n",
    "\n",
    "# üè∑ Î≤îÏ£ºÌòï\n",
    "cat_cols = [\n",
    "    \"Í≥µÌï≠Î™Ö\",\n",
    "    \"Ï∂úÎ∞úÏßÄ\",\n",
    "    \"ÎèÑÏ∞©ÏßÄ\",\n",
    "    \"flight_type\"\n",
    "]\n",
    "cat_cols = [c for c in cat_cols if c in df.columns]\n",
    "\n",
    "X_cols = num_cols + cat_cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0d0127c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-21T08:28:16.466700Z",
     "start_time": "2026-01-21T08:28:15.050552Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 2275147 Test: 568787\n"
     ]
    }
   ],
   "source": [
    "df = df.sort_values(\"departure_datetime\")\n",
    "split_date = df[\"departure_datetime\"].quantile(0.8)\n",
    "\n",
    "train_df = df[df[\"departure_datetime\"] <= split_date]\n",
    "test_df  = df[df[\"departure_datetime\"] > split_date]\n",
    "\n",
    "X_train = train_df[X_cols]\n",
    "y_train = train_df[\"is_delay\"]\n",
    "\n",
    "X_test  = test_df[X_cols]\n",
    "y_test  = test_df[\"is_delay\"]\n",
    "\n",
    "print(\"Train:\", len(train_df), \"Test:\", len(test_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a493f4ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-21T08:32:05.457634Z",
     "start_time": "2026-01-21T08:28:16.467694Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\envs\\4vector\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Logistic (threshold=0.4)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.38      0.53    422243\n",
      "           1       0.31      0.82      0.45    146544\n",
      "\n",
      "    accuracy                           0.49    568787\n",
      "   macro avg       0.59      0.60      0.49    568787\n",
      "weighted avg       0.72      0.49      0.51    568787\n",
      "\n",
      "ROC-AUC: 0.6474615621075573\n",
      "PR-AUC : 0.3721759150947776\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "num_pipe = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\"))\n",
    "])\n",
    "\n",
    "cat_pipe = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"UNKNOWN\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\", sparse=True))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"num\", num_pipe, num_cols),\n",
    "    (\"cat\", cat_pipe, cat_cols)\n",
    "])\n",
    "\n",
    "logistic = Pipeline([\n",
    "    (\"prep\", preprocessor),\n",
    "    (\"clf\", LogisticRegression(\n",
    "        max_iter=3000,\n",
    "        class_weight=\"balanced\",\n",
    "        n_jobs=-1\n",
    "    ))\n",
    "])\n",
    "\n",
    "logistic.fit(X_train, y_train)\n",
    "\n",
    "log_prob = logistic.predict_proba(X_test)[:, 1]\n",
    "log_pred = (log_prob >= 0.4).astype(int)\n",
    "\n",
    "print(\"\\nüìä Logistic (threshold=0.4)\")\n",
    "print(classification_report(y_test, log_pred))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, log_prob))\n",
    "print(\"PR-AUC :\", average_precision_score(y_test, log_prob))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f61b0155",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-21T08:32:34.971551Z",
     "start_time": "2026-01-21T08:32:05.458871Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\envs\\4vector\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä XGBoost (threshold=0.4)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.43      0.57    422243\n",
      "           1       0.34      0.83      0.48    146544\n",
      "\n",
      "    accuracy                           0.53    568787\n",
      "   macro avg       0.61      0.63      0.53    568787\n",
      "weighted avg       0.74      0.53      0.55    568787\n",
      "\n",
      "ROC-AUC: 0.6854605778465136\n",
      "PR-AUC : 0.4262482943255317\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb = XGBClassifier(\n",
    "    n_estimators=400,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "\n",
    "    scale_pos_weight=(y_train == 0).sum() / (y_train == 1).sum(),\n",
    "    objective=\"binary:logistic\",\n",
    "    eval_metric=\"aucpr\",\n",
    "    tree_method=\"hist\",\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "xgb_model = Pipeline([\n",
    "    (\"prep\", preprocessor),\n",
    "    (\"xgb\", xgb)\n",
    "])\n",
    "\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "xgb_prob = xgb_model.predict_proba(X_test)[:, 1]\n",
    "xgb_pred = (xgb_prob >= 0.4).astype(int)\n",
    "\n",
    "print(\"\\nüìä XGBoost (threshold=0.4)\")\n",
    "print(classification_report(y_test, xgb_pred))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, xgb_prob))\n",
    "print(\"PR-AUC :\", average_precision_score(y_test, xgb_prob))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ad79f84",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-21T08:33:07.720649Z",
     "start_time": "2026-01-21T08:32:34.972551Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 336343, number of negative: 1938804\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014151 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 661\n",
      "[LightGBM] [Info] Number of data points in the train set: 2275147, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "\n",
      "üìä LightGBM (threshold=0.4)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.48      0.62    422243\n",
      "           1       0.35      0.80      0.49    146544\n",
      "\n",
      "    accuracy                           0.56    568787\n",
      "   macro avg       0.61      0.64      0.55    568787\n",
      "weighted avg       0.74      0.56      0.58    568787\n",
      "\n",
      "ROC-AUC: 0.7059227082554224\n",
      "PR-AUC : 0.4578427366604109\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# LightGBMÏö© category Î≥ÄÌôò\n",
    "for c in cat_cols:\n",
    "    df[c] = df[c].astype(\"category\")\n",
    "\n",
    "train_df = df[df[\"departure_datetime\"] <= split_date]\n",
    "test_df  = df[df[\"departure_datetime\"] > split_date]\n",
    "\n",
    "X_train_lgb = train_df[X_cols]\n",
    "y_train_lgb = train_df[\"is_delay\"]\n",
    "\n",
    "X_test_lgb  = test_df[X_cols]\n",
    "y_test_lgb  = test_df[\"is_delay\"]\n",
    "\n",
    "lgbm = LGBMClassifier(\n",
    "    n_estimators=500,\n",
    "    learning_rate=0.05,\n",
    "    num_leaves=64,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "\n",
    "    class_weight=\"balanced\",\n",
    "    objective=\"binary\",\n",
    "    metric=\"aucpr\",\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "lgbm.fit(\n",
    "    X_train_lgb,\n",
    "    y_train_lgb,\n",
    "    categorical_feature=cat_cols\n",
    ")\n",
    "\n",
    "lgb_prob = lgbm.predict_proba(X_test_lgb)[:, 1]\n",
    "lgb_pred = (lgb_prob >= 0.4).astype(int)\n",
    "\n",
    "print(\"\\nüìä LightGBM (threshold=0.4)\")\n",
    "print(classification_report(y_test_lgb, lgb_pred))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test_lgb, lgb_prob))\n",
    "print(\"PR-AUC :\", average_precision_score(y_test_lgb, lgb_prob))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da23d4b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-21T08:33:08.617298Z",
     "start_time": "2026-01-21T08:33:07.722600Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>ROC-AUC</th>\n",
       "      <th>PR-AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic</td>\n",
       "      <td>0.647462</td>\n",
       "      <td>0.372176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.685461</td>\n",
       "      <td>0.426248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.705923</td>\n",
       "      <td>0.457843</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Model   ROC-AUC    PR-AUC\n",
       "0  Logistic  0.647462  0.372176\n",
       "1   XGBoost  0.685461  0.426248\n",
       "2  LightGBM  0.705923  0.457843"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary = pd.DataFrame([\n",
    "    [\"Logistic\", roc_auc_score(y_test, log_prob), average_precision_score(y_test, log_prob)],\n",
    "    [\"XGBoost\",  roc_auc_score(y_test, xgb_prob), average_precision_score(y_test, xgb_prob)],\n",
    "    [\"LightGBM\", roc_auc_score(y_test_lgb, lgb_prob), average_precision_score(y_test_lgb, lgb_prob)]\n",
    "], columns=[\"Model\", \"ROC-AUC\", \"PR-AUC\"])\n",
    "\n",
    "summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110d4d79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2e4622",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä ÏãúÍ∞ÅÌôî: ÏÑ±Îä• ÏöîÏïΩ Ìëú & Í∑∏ÎûòÌîÑ\n",
    "\n",
    "ÏïÑÎûò ÏÖÄÎì§ÏùÄ **Í∏∞Ï°¥ ÏΩîÎìú(ÌïôÏäµ/ÏòàÏ∏°/ÌèâÍ∞Ä)** Ïã§ÌñâÏù¥ ÎÅùÎÇú Îí§, Îß® ÏïÑÎûòÏóêÏÑú Ï∂îÍ∞ÄÎ°ú Ïã§ÌñâÌïòÎ©¥ Îê©ÎãàÎã§.  \n",
    "(Í∏∞Ï°¥ ÏΩîÎìúÎäî Í∑∏ÎåÄÎ°ú Ïú†ÏßÄÌñàÍ≥†, ÏãúÍ∞ÅÌôîÎßå \"Ï∂îÍ∞Ä\"ÌñàÏäµÎãàÎã§.)\n"
   ],
   "id": "54ce7935"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# =====================================================\n",
    "# üìå ÏãúÍ∞ÅÌôî Ï§ÄÎπÑ: Î≥ÄÏàò ÏûêÎèô ÌÉêÏÉâ + Í∏∞Î≥∏ ÏÑ±Îä• ÏöîÏïΩ Ìëú ÏÉùÏÑ±\n",
    "# -----------------------------------------------------\n",
    "# ‚úÖ Ïù¥ ÏÖÄÏùÄ \"Í∏∞Ï°¥ ÏΩîÎìú\"ÏóêÏÑú ÎßåÎì† Î≥ÄÏàòÎì§ÏùÑ ÏµúÎåÄÌïú ÏûêÎèôÏúºÎ°ú Ï∞æÏïÑÏÑú,\n",
    "#    - y_true (Ï†ïÎãµ)\n",
    "#    - y_proba (ÏòàÏ∏° ÌôïÎ•†)\n",
    "#    - y_pred (ÏòàÏ∏° ÎùºÎ≤®)\n",
    "#    - model (ÌïôÏäµ Î™®Îç∏)\n",
    "#    - X_test (ÌÖåÏä§Ìä∏ ÎèÖÎ¶ΩÎ≥ÄÏàò)\n",
    "# Î•º ÌôïÎ≥¥Ìïú Îí§, ÌëúÎ°ú Ï†ïÎ¶¨Ìï©ÎãàÎã§.\n",
    "#\n",
    "# ‚ö†Ô∏è ÎÖ∏Ìä∏Î∂ÅÎßàÎã§ Î≥ÄÏàòÎ™ÖÏù¥ Ï°∞Í∏àÏî© Îã§Î•º Ïàò ÏûàÏñ¥ÏÑú,\n",
    "#    ÏïÑÎûò ÏΩîÎìúÍ∞Ä Ïó¨Îü¨ ÌõÑÎ≥¥ Ïù¥Î¶ÑÏùÑ ÏàúÏÑúÎåÄÎ°ú ÌÉêÏÉâÌï©ÎãàÎã§.\n",
    "# =====================================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    average_precision_score\n",
    ")\n",
    "\n",
    "def _pick_first_existing(name_candidates):\n",
    "    # Ïó¨Îü¨ Î≥ÄÏàòÎ™Ö ÌõÑÎ≥¥ Ï§ëÏóêÏÑú ÌòÑÏû¨ ÎÖ∏Ìä∏Î∂Å Ïã§Ìñâ ÌôòÍ≤Ω(globals)Ïóê Ï°¥Ïû¨ÌïòÎäî\n",
    "    # 'Ï≤´ Î≤àÏß∏' Î≥ÄÏàòÎ•º Ï∞æÏïÑ (Í∞í, Î≥ÄÏàòÎ™Ö) ÌòïÌÉúÎ°ú Î∞òÌôò\n",
    "    for n in name_candidates:\n",
    "        if n in globals():\n",
    "            return globals()[n], n\n",
    "    return None, None\n",
    "\n",
    "def _as_1d_array(x):\n",
    "    # Î¶¨Ïä§Ìä∏/ÏãúÎ¶¨Ï¶à/ÎÑòÌååÏù¥ Îì± -> 1Ï∞®Ïõê np.arrayÎ°ú ÏïàÏ†ÑÌïòÍ≤å Î≥ÄÌôò\n",
    "    if x is None:\n",
    "        return None\n",
    "    try:\n",
    "        arr = np.array(x)\n",
    "        # (N,1) ÎòêÎäî (1,N) Í∞ôÏùÄ ÌòïÌÉúÎ©¥ 1Ï∞®ÏõêÏúºÎ°ú ÌéºÏπ®\n",
    "        return arr.reshape(-1)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 1) y_true(Ï†ïÎãµ) ÏûêÎèô ÌÉêÏÉâ\n",
    "# -----------------------------------------------------\n",
    "y_true, y_true_name = _pick_first_existing([\n",
    "    \"y_test\", \"test_y\", \"y_valid\", \"y_val\", \"y_true\", \"Y_test\", \"Y_val\"\n",
    "])\n",
    "y_true = _as_1d_array(y_true)\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 2) X_test(ÌÖåÏä§Ìä∏ ÎèÖÎ¶ΩÎ≥ÄÏàò) ÏûêÎèô ÌÉêÏÉâ (ÌîºÏ≤òÎ™Ö Ï∂îÏ∂úÏö©)\n",
    "# -----------------------------------------------------\n",
    "X_test, X_test_name = _pick_first_existing([\n",
    "    \"X_test\", \"test_X\", \"X_valid\", \"X_val\", \"X_te\", \"x_test\"\n",
    "])\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 3) model(ÌïôÏäµ Î™®Îç∏) ÏûêÎèô ÌÉêÏÉâ\n",
    "# -----------------------------------------------------\n",
    "# ‚úÖ ÎπÑÍµê ÎÖ∏Ìä∏Î∂Å(Ïó¨Îü¨ Î™®Îç∏)ÎèÑ ÏûàÏùÑ Ïàò ÏûàÏñ¥ÏÑú, ÌùîÌïú Ïù¥Î¶ÑÎì§ÏùÑ ÎÑìÍ≤å ÌÉêÏÉâÌï©ÎãàÎã§.\n",
    "model, model_name = _pick_first_existing([\n",
    "    \"model\", \"clf\", \"classifier\",\n",
    "    \"lgb_model\", \"lgbm_model\", \"lgbm\",\n",
    "    \"xgb_model\", \"xgb\", \"xgb_clf\",\n",
    "    \"best_model\", \"final_model\"\n",
    "])\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 4) y_proba(ÏòàÏ∏° ÌôïÎ•†) ÏûêÎèô ÌÉêÏÉâ\n",
    "# -----------------------------------------------------\n",
    "# ‚úÖ Ïù¥ÎØ∏ ÎßåÎì§Ïñ¥Îëî ÌôïÎ•† Î≥ÄÏàòÍ∞Ä ÏûàÏúºÎ©¥ Í∑∏Í±∏ Ïö∞ÏÑ† ÏÇ¨Ïö©Ìï©ÎãàÎã§.\n",
    "y_proba, y_proba_name = _pick_first_existing([\n",
    "    \"y_proba\", \"y_pred_proba\", \"pred_proba\", \"proba\",\n",
    "    \"y_score\", \"scores\", \"prob\", \"p_pred\"\n",
    "])\n",
    "\n",
    "# ‚úÖ ÌôïÎ•† Î≥ÄÏàòÍ∞Ä ÏóÜÏúºÎ©¥, model + X_testÎ°ú ÏßÅÏ†ë Í≥ÑÏÇ∞ÏùÑ ÏãúÎèÑÌï©ÎãàÎã§.\n",
    "if y_proba is None and model is not None and X_test is not None:\n",
    "    try:\n",
    "        # sklearn / xgboost / lightgbm ÎåÄÎ∂ÄÎ∂ÑÏùÄ predict_proba ÏßÄÏõê\n",
    "        if hasattr(model, \"predict_proba\"):\n",
    "            proba = model.predict_proba(X_test)\n",
    "            # Î≥¥ÌÜµ Ïù¥ÏßÑÎ∂ÑÎ•òÎäî (N, 2) -> positive class ÌôïÎ•†ÏùÄ [:, 1]\n",
    "            if isinstance(proba, np.ndarray) and proba.ndim == 2 and proba.shape[1] >= 2:\n",
    "                y_proba = proba[:, 1]\n",
    "                y_proba_name = f\"{model_name}.predict_proba({X_test_name})[:,1]\"\n",
    "            else:\n",
    "                # ÌòπÏãú (N,)ÏúºÎ°ú Î∞îÎ°ú ÎÇòÏò§Îäî Í≤ΩÏö∞\n",
    "                y_proba = proba\n",
    "                y_proba_name = f\"{model_name}.predict_proba({X_test_name})\"\n",
    "        # decision_functionÎßå ÏûàÎäî Î™®Îç∏ÎèÑ Ï°¥Ïû¨Ìï† Ïàò ÏûàÏùå (SVM Îì±)\n",
    "        elif hasattr(model, \"decision_function\"):\n",
    "            score = model.decision_function(X_test)\n",
    "            y_proba = score\n",
    "            y_proba_name = f\"{model_name}.decision_function({X_test_name})\"\n",
    "    except Exception as e:\n",
    "        print(\"‚ö†Ô∏è modelÎ°úÎ∂ÄÌÑ∞ ÏòàÏ∏° ÌôïÎ•†(y_proba) Í≥ÑÏÇ∞ Ïã§Ìå®:\", repr(e))\n",
    "\n",
    "y_proba = _as_1d_array(y_proba)\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 5) y_pred(ÏòàÏ∏° ÎùºÎ≤®) ÏûêÎèô ÌÉêÏÉâ\n",
    "# -----------------------------------------------------\n",
    "y_pred, y_pred_name = _pick_first_existing([\n",
    "    \"y_pred\", \"pred\", \"y_hat\", \"y_pred_label\"\n",
    "])\n",
    "\n",
    "# ‚úÖ y_predÍ∞Ä ÏóÜÏúºÎ©¥, y_probaÎ°ú threshold=0.5 Í∏∞Ï§Ä ÎùºÎ≤® ÏÉùÏÑ±\n",
    "if y_pred is None and y_proba is not None:\n",
    "    y_pred = (y_proba >= 0.5).astype(int)\n",
    "    y_pred_name = \"derived_from_y_proba(threshold=0.5)\"\n",
    "\n",
    "y_pred = _as_1d_array(y_pred)\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 6) ÌôïÎ≥¥Ìïú Î≥ÄÏàòÎì§ ÏöîÏïΩ Ï∂úÎ†•\n",
    "# -----------------------------------------------------\n",
    "print(\"‚úÖ [ÏûêÎèô ÌÉêÏÉâ Í≤∞Í≥º]\")\n",
    "print(f\" - y_true  : {y_true_name}\")\n",
    "print(f\" - y_proba : {y_proba_name}\")\n",
    "print(f\" - y_pred  : {y_pred_name}\")\n",
    "print(f\" - model   : {model_name}\")\n",
    "print(f\" - X_test  : {X_test_name}\")\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 7) Í∏∞Î≥∏ ÏÑ±Îä• ÏöîÏïΩ Ìëú(Ïù¥ÏßÑÎ∂ÑÎ•ò Í∏∞Ï§Ä)\n",
    "# -----------------------------------------------------\n",
    "# ‚ö†Ô∏è y_true ÎòêÎäî y_predÍ∞Ä ÏóÜÏúºÎ©¥ ÌëúÎ•º ÎßåÎì§ Ïàò ÏóÜÏúºÎãà ÏïàÎÇ¥ ÌõÑ Ï¢ÖÎ£åÌï©ÎãàÎã§.\n",
    "if y_true is None or y_pred is None:\n",
    "    raise ValueError(\"y_true ÎòêÎäî y_predÎ•º Ï∞æÏßÄ Î™ªÌñàÏäµÎãàÎã§. (Í∏∞Ï°¥ ÏΩîÎìúÏóêÏÑú test Ï†ïÎãµ/ÏòàÏ∏° Î≥ÄÏàòÎ•º ÎßåÎì† Îí§ Îã§Ïãú Ïã§ÌñâÌïòÏÑ∏Ïöî.)\")\n",
    "\n",
    "# ‚úÖ classification_reportÎ•º DataFrameÏúºÎ°ú Î≥ÄÌôò (ÌëúÎ°ú Î≥¥Í∏∞ Ï¢ãÍ≤å)\n",
    "report_dict = classification_report(y_true, y_pred, output_dict=True, zero_division=0)\n",
    "report_df = pd.DataFrame(report_dict).T\n",
    "\n",
    "# ‚úÖ Ï†ÑÏ≤¥ Ïä§ÏπºÎùº ÏßÄÌëú(ÏûàÏùÑ ÎïåÎßå Í≥ÑÏÇ∞)\n",
    "metrics = {\n",
    "    \"accuracy\": accuracy_score(y_true, y_pred),\n",
    "    \"precision(binary)\": precision_score(y_true, y_pred, zero_division=0),\n",
    "    \"recall(binary)\": recall_score(y_true, y_pred, zero_division=0),\n",
    "    \"f1(binary)\": f1_score(y_true, y_pred, zero_division=0),\n",
    "}\n",
    "\n",
    "# ‚úÖ ÌôïÎ•†Ïù¥ ÏûàÏúºÎ©¥ ROC-AUC / PR-AUCÎèÑ Í≥ÑÏÇ∞\n",
    "if y_proba is not None:\n",
    "    try:\n",
    "        metrics[\"roc_auc\"] = roc_auc_score(y_true, y_proba)\n",
    "    except Exception:\n",
    "        metrics[\"roc_auc\"] = np.nan\n",
    "    try:\n",
    "        metrics[\"pr_auc(AP)\"] = average_precision_score(y_true, y_proba)\n",
    "    except Exception:\n",
    "        metrics[\"pr_auc(AP)\"] = np.nan\n",
    "else:\n",
    "    metrics[\"roc_auc\"] = np.nan\n",
    "    metrics[\"pr_auc(AP)\"] = np.nan\n",
    "\n",
    "metrics_df = pd.DataFrame([metrics])\n",
    "\n",
    "print(\"\\n‚úÖ [ÏÑ±Îä• ÏöîÏïΩ(Ïä§ÏπºÎùº)]\")\n",
    "display(metrics_df)\n",
    "\n",
    "print(\"\\n‚úÖ [Classification Report (Ìëú)]\")\n",
    "display(report_df)\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 8) Confusion Matrix(ÌòºÎèôÌñâÎ†¨) Ìëú\n",
    "# -----------------------------------------------------\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "cm_df = pd.DataFrame(cm, index=[\"Actual 0\", \"Actual 1\"], columns=[\"Pred 0\", \"Pred 1\"])\n",
    "\n",
    "print(\"\\n‚úÖ [Confusion Matrix (Ìëú)]\")\n",
    "display(cm_df)\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 9) Threshold(ÏûÑÍ≥ÑÍ∞í) Ïä§Ïúï ÌÖåÏù¥Î∏î\n",
    "# -----------------------------------------------------\n",
    "# ‚úÖ ÌôïÎ•†(y_proba)Ïù¥ ÏûàÏùÑ ÎïåÎßå ÏùòÎØ∏Í∞Ä ÏûàÏúºÎØÄÎ°ú, ÏóÜÏúºÎ©¥ Ïä§ÌÇµÌï©ÎãàÎã§.\n",
    "if y_proba is not None:\n",
    "    thresholds = np.linspace(0.05, 0.95, 19)\n",
    "    rows = []\n",
    "    for t in thresholds:\n",
    "        yp = (y_proba >= t).astype(int)\n",
    "        rows.append({\n",
    "            \"threshold\": float(np.round(t, 2)),\n",
    "            \"accuracy\": accuracy_score(y_true, yp),\n",
    "            \"precision\": precision_score(y_true, yp, zero_division=0),\n",
    "            \"recall\": recall_score(y_true, yp, zero_division=0),\n",
    "            \"f1\": f1_score(y_true, yp, zero_division=0),\n",
    "        })\n",
    "    thr_df = pd.DataFrame(rows).sort_values(\"threshold\")\n",
    "    print(\"\\n‚úÖ [Threshold Ïä§Ïúï ÏÑ±Îä• Ìëú] (ÌôïÎ•† Í∏∞Î∞ò)\")\n",
    "    display(thr_df)\n",
    "else:\n",
    "    thr_df = None\n",
    "    print(\"\\n‚ÑπÔ∏è y_proba(ÏòàÏ∏° ÌôïÎ•†)Í∞Ä ÏóÜÏñ¥ threshold Ïä§Ïúï ÌëúÎäî ÏÉùÎûµÌï©ÎãàÎã§.\")\n"
   ],
   "outputs": [],
   "execution_count": null,
   "id": "f0a061bf"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# =====================================================\n",
    "# üìà ÏãúÍ∞ÅÌôî: ÌòºÎèôÌñâÎ†¨ / ROC / PR / ÌôïÎ•†Î∂ÑÌè¨ / ÏûÑÍ≥ÑÍ∞í Í≥°ÏÑ† / Ï§ëÏöî ÌîºÏ≤ò\n",
    "# -----------------------------------------------------\n",
    "# ‚úÖ Ïù¥ ÏÖÄÏùÄ ÏúÑ ÏÖÄÏóêÏÑú ÎßåÎì†(ÎòêÎäî Ï∞æÏùÄ) Î≥ÄÏàò(y_true, y_pred, y_proba, model, X_test)Î•º ÏÇ¨Ïö©Ìï©ÎãàÎã§.\n",
    "# ‚úÖ Í∑∏ÎûòÌîÑÎäî matplotlib Í∏∞Î≥∏ Ïä§ÌÉÄÏùº(ÏÉâ ÏßÄÏ†ï ÏóÜÏùå)Î°ú Í∑∏Î¶ΩÎãàÎã§.\n",
    "# =====================================================\n",
    "\n",
    "from sklearn.metrics import roc_curve, precision_recall_curve\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 1) ÌòºÎèôÌñâÎ†¨(Confusion Matrix) ÏãúÍ∞ÅÌôî\n",
    "# -----------------------------------------------------\n",
    "plt.figure(figsize=(5, 4))\n",
    "plt.imshow(cm, interpolation=\"nearest\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.colorbar()\n",
    "\n",
    "tick_marks = np.arange(2)\n",
    "plt.xticks(tick_marks, [\"Pred 0\", \"Pred 1\"])\n",
    "plt.yticks(tick_marks, [\"Actual 0\", \"Actual 1\"])\n",
    "\n",
    "# ‚úÖ ÏÖÄ ÏïàÏóê Ïà´Ïûê(Í±¥Ïàò) ÌëúÏãú\n",
    "for i in range(cm.shape[0]):\n",
    "    for j in range(cm.shape[1]):\n",
    "        plt.text(j, i, str(cm[i, j]), ha=\"center\", va=\"center\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 2) ROC Curve (ÌôïÎ•†Ïù¥ ÏûàÏùÑ ÎïåÎßå)\n",
    "# -----------------------------------------------------\n",
    "if y_proba is not None:\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_proba)\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.plot(fpr, tpr, label=\"ROC\")\n",
    "    plt.plot([0, 1], [0, 1], linestyle=\"--\", label=\"Random\")\n",
    "    plt.title(\"ROC Curve\")\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 3) Precision-Recall Curve (ÌôïÎ•†Ïù¥ ÏûàÏùÑ ÎïåÎßå)\n",
    "# -----------------------------------------------------\n",
    "if y_proba is not None:\n",
    "    precision, recall, _ = precision_recall_curve(y_true, y_proba)\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.plot(recall, precision, label=\"PR\")\n",
    "    plt.title(\"Precision-Recall Curve\")\n",
    "    plt.xlabel(\"Recall\")\n",
    "    plt.ylabel(\"Precision\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 4) ÏòàÏ∏° ÌôïÎ•† Î∂ÑÌè¨(ÌÅ¥ÎûòÏä§Î≥Ñ) (ÌôïÎ•†Ïù¥ ÏûàÏùÑ ÎïåÎßå)\n",
    "# -----------------------------------------------------\n",
    "# ‚úÖ ÌÅ¥ÎûòÏä§ 0Í≥º 1Ïùò ÏòàÏ∏° ÌôïÎ•† Î∂ÑÌè¨Î•º Îî∞Î°ú Í∑∏Î¶¨Î©¥,\n",
    "#    Î™®Îç∏Ïù¥ Ïñ¥Îäê Ï†ïÎèÑÎ°ú Îëê ÌÅ¥ÎûòÏä§Î•º \"Î∂ÑÎ¶¨\"ÌïòÎäîÏßÄ ÏßÅÍ¥ÄÏ†ÅÏúºÎ°ú ÌôïÏù∏ Í∞ÄÎä•Ìï©ÎãàÎã§.\n",
    "if y_proba is not None:\n",
    "    y_proba_0 = y_proba[y_true == 0]\n",
    "    y_proba_1 = y_proba[y_true == 1]\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.hist(y_proba_0, bins=50, alpha=0.6, label=\"Actual 0\")\n",
    "    plt.hist(y_proba_1, bins=50, alpha=0.6, label=\"Actual 1\")\n",
    "    plt.title(\"Predicted Probability Distribution\")\n",
    "    plt.xlabel(\"Predicted probability (positive class)\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 5) Threshold(ÏûÑÍ≥ÑÍ∞í) Î≥ÄÌôîÏóê Îî∞Î•∏ Precision/Recall/F1 Í≥°ÏÑ† (ÌôïÎ•†Ïù¥ ÏûàÏùÑ ÎïåÎßå)\n",
    "# -----------------------------------------------------\n",
    "if thr_df is not None:\n",
    "    plt.figure(figsize=(7, 4))\n",
    "    plt.plot(thr_df[\"threshold\"], thr_df[\"precision\"], label=\"precision\")\n",
    "    plt.plot(thr_df[\"threshold\"], thr_df[\"recall\"], label=\"recall\")\n",
    "    plt.plot(thr_df[\"threshold\"], thr_df[\"f1\"], label=\"f1\")\n",
    "    plt.title(\"Precision / Recall / F1 vs Threshold\")\n",
    "    plt.xlabel(\"Threshold\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 6) Ï§ëÏöî ÌîºÏ≤ò(Feature Importance / Coef) Top 20\n",
    "# -----------------------------------------------------\n",
    "# ‚úÖ Ìä∏Î¶¨ Í∏∞Î∞ò Î™®Îç∏(lightgbm/xgboost Îì±): feature_importances_\n",
    "# ‚úÖ ÏÑ†Ìòï Î™®Îç∏(logistic regression Îì±): coef_\n",
    "#\n",
    "# ‚ö†Ô∏è ÌîºÏ≤òÎ™ÖÏù¥ ÌïÑÏöîÌï©ÎãàÎã§. Î≥¥ÌÜµ X_testÍ∞Ä DataFrameÏù¥Î©¥ columnsÎ°ú Í∞ÄÏ†∏ÏòµÎãàÎã§.\n",
    "#    (numpy arrayÏù¥Î©¥, ÌîºÏ≤òÎ™ÖÏùÑ Î™®Î•º Ïàò ÏûàÏñ¥ indexÎ°ú ÌëúÏãúÌï©ÎãàÎã§.)\n",
    "# -----------------------------------------------------\n",
    "feature_names = None\n",
    "if X_test is not None:\n",
    "    try:\n",
    "        if hasattr(X_test, \"columns\"):\n",
    "            feature_names = list(X_test.columns)\n",
    "        else:\n",
    "            # numpy arrayÏù∏ Í≤ΩÏö∞: ÌîºÏ≤òÎ™Ö ÏóÜÏùå -> Î≤àÌò∏Î°ú ÎåÄÏ≤¥\n",
    "            feature_names = [f\"f{i}\" for i in range(X_test.shape[1])]\n",
    "    except Exception:\n",
    "        feature_names = None\n",
    "\n",
    "def _plot_top_features(values, names, title, top_n=20):\n",
    "    # Ï§ëÏöîÎèÑ/Í≥ÑÏàò Î∞∞Ïó¥(values)ÏôÄ ÌîºÏ≤òÎ™Ö(names)ÏúºÎ°ú Top-N ÎßâÎåÄÍ∑∏ÎûòÌîÑÎ•º Í∑∏Î¶ΩÎãàÎã§.\n",
    "    # - values: (num_features,) ÌòïÌÉú\n",
    "    # - names : Í∏∏Ïù¥ num_features\n",
    "    s = pd.Series(values, index=names)\n",
    "    # Ï†àÎåÄÍ∞í Í∏∞Ï§Ä Top-N (Ïñë/Ïùå Î™®Îëê Ï§ëÏöîÌï† Ïàò ÏûàÏñ¥ÏÑú)\n",
    "    top = s.reindex(s.abs().sort_values(ascending=False).index).head(top_n)\n",
    "    top = top.iloc[::-1]  # Î≥¥Í∏∞ Ï¢ãÍ≤å Ïó≠Ïàú\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.barh(top.index, top.values)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Importance / Coefficient\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# ‚úÖ modelÏù¥ Ï°¥Ïû¨ÌïòÍ≥†, feature_namesÍ∞Ä ÏûàÏùÑ ÎïåÎßå ÏãúÍ∞ÅÌôî ÏãúÎèÑ\n",
    "if model is not None and feature_names is not None:\n",
    "    try:\n",
    "        # 6-A) Ìä∏Î¶¨ Í∏∞Î∞ò importance\n",
    "        if hasattr(model, \"feature_importances_\"):\n",
    "            imp = np.array(model.feature_importances_).reshape(-1)\n",
    "            if len(imp) == len(feature_names):\n",
    "                _plot_top_features(imp, feature_names, \"Top Features (feature_importances_)\")\n",
    "            else:\n",
    "                print(\"‚ö†Ô∏è feature_importances_ Í∏∏Ïù¥ÏôÄ feature_names Í∏∏Ïù¥Í∞Ä Îã¨Îùº importance ÏãúÍ∞ÅÌôîÎ•º ÏÉùÎûµÌï©ÎãàÎã§.\")\n",
    "        # 6-B) ÏÑ†Ìòï Î™®Îç∏ coef\n",
    "        elif hasattr(model, \"coef_\"):\n",
    "            coef = np.array(model.coef_).reshape(-1)\n",
    "            if len(coef) == len(feature_names):\n",
    "                _plot_top_features(coef, feature_names, \"Top Features (coef_)\")\n",
    "            else:\n",
    "                print(\"‚ö†Ô∏è coef_ Í∏∏Ïù¥ÏôÄ feature_names Í∏∏Ïù¥Í∞Ä Îã¨Îùº coef ÏãúÍ∞ÅÌôîÎ•º ÏÉùÎûµÌï©ÎãàÎã§.\")\n",
    "        else:\n",
    "            print(\"‚ÑπÔ∏è Ïù¥ Î™®Îç∏ÏùÄ feature_importances_ ÎòêÎäî coef_Í∞Ä ÏóÜÏñ¥ Ï§ëÏöî ÌîºÏ≤ò ÏãúÍ∞ÅÌôîÎ•º ÏÉùÎûµÌï©ÎãàÎã§.\")\n",
    "    except Exception as e:\n",
    "        print(\"‚ö†Ô∏è Ï§ëÏöî ÌîºÏ≤ò ÏãúÍ∞ÅÌôî Ï§ë Ïò§Î•ò:\", repr(e))\n",
    "else:\n",
    "    print(\"‚ÑπÔ∏è model ÎòêÎäî feature_namesÎ•º ÌôïÎ≥¥ÌïòÏßÄ Î™ªÌï¥ Ï§ëÏöî ÌîºÏ≤ò ÏãúÍ∞ÅÌôîÎ•º ÏÉùÎûµÌï©ÎãàÎã§.\")\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 7) (ÏòµÏÖò) Ïó¨Îü¨ Î™®Îç∏ ÎπÑÍµêÍ∞Ä Í∞ÄÎä•Ìïú Í≤ΩÏö∞: models(dict)Í∞Ä ÏûàÏúºÎ©¥ ÏÑ±Îä•Ìëú ÏÉùÏÑ±\n",
    "# -----------------------------------------------------\n",
    "# ‚úÖ ÎπÑÍµê ÎÖ∏Ìä∏Î∂ÅÏóêÏÑú models = {\"lgb\":..., \"xgb\":..., ...} ÌòïÌÉúÎ°ú Í∞ÄÏßÄÍ≥† ÏûàÎäî Í≤ΩÏö∞Í∞Ä ÏûàÏñ¥ÏÑú\n",
    "#    ÏûàÏúºÎ©¥ ÏûêÎèôÏúºÎ°ú ÎèåÎ†§ÏÑú ÌëúÎ•º ÎßåÎì§Ïñ¥ Ï§çÎãàÎã§.\n",
    "# -----------------------------------------------------\n",
    "models_dict = globals().get(\"models\", None)\n",
    "\n",
    "if isinstance(models_dict, dict) and X_test is not None and y_true is not None:\n",
    "    rows = []\n",
    "    for k, m in models_dict.items():\n",
    "        try:\n",
    "            # ÏòàÏ∏° ÌôïÎ•† Í≥ÑÏÇ∞\n",
    "            if hasattr(m, \"predict_proba\"):\n",
    "                p = m.predict_proba(X_test)\n",
    "                if isinstance(p, np.ndarray) and p.ndim == 2 and p.shape[1] >= 2:\n",
    "                    p = p[:, 1]\n",
    "            elif hasattr(m, \"decision_function\"):\n",
    "                p = m.decision_function(X_test)\n",
    "            else:\n",
    "                p = None\n",
    "\n",
    "            # ÏòàÏ∏° ÎùºÎ≤®(Í∏∞Î≥∏ threshold=0.5)\n",
    "            if p is not None:\n",
    "                yp = (np.array(p).reshape(-1) >= 0.5).astype(int)\n",
    "                roc = roc_auc_score(y_true, p)\n",
    "                pr = average_precision_score(y_true, p)\n",
    "            else:\n",
    "                yp = m.predict(X_test)\n",
    "                roc = np.nan\n",
    "                pr = np.nan\n",
    "\n",
    "            rows.append({\n",
    "                \"model_name\": k,\n",
    "                \"accuracy\": accuracy_score(y_true, yp),\n",
    "                \"precision\": precision_score(y_true, yp, zero_division=0),\n",
    "                \"recall\": recall_score(y_true, yp, zero_division=0),\n",
    "                \"f1\": f1_score(y_true, yp, zero_division=0),\n",
    "                \"roc_auc\": roc,\n",
    "                \"pr_auc(AP)\": pr\n",
    "            })\n",
    "        except Exception as e:\n",
    "            rows.append({\"model_name\": k, \"error\": repr(e)})\n",
    "\n",
    "    compare_df = pd.DataFrame(rows)\n",
    "    print(\"\\n‚úÖ [Ïó¨Îü¨ Î™®Îç∏ ÎπÑÍµê ÏÑ±Îä•Ìëú]\")\n",
    "    display(compare_df)\n"
   ],
   "outputs": [],
   "execution_count": null,
   "id": "1866a3e5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "4vector(ipykernel)",
   "language": "python",
   "name": "4vector"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}