{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0b17508",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-22T04:00:28.223020Z",
     "start_time": "2026-01-22T03:59:53.591804Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_16464\\4080722524.py:9: DtypeWarning: Columns (28,49) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"new_flight_weather_merged.csv\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ï†ÑÏ≤¥ Îç∞Ïù¥ÌÑ∞ Ïàò: 2843934\n",
      "Train: 2275147 Test: 568787\n",
      "Before Downsampling\n",
      "Ï†ïÏÉÅ(0): 1938804 ÏßÄÏó∞(1): 336343\n",
      "After Downsampling\n",
      "0    336343\n",
      "1    336343\n",
      "Name: is_delay, dtype: int64\n",
      "[LightGBM] [Info] Number of positive: 336343, number of negative: 336343\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013337 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 664\n",
      "[LightGBM] [Info] Number of data points in the train set: 672686, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "‚úÖ LightGBM (Downsampling) ÌïôÏäµ ÏôÑÎ£å\n",
      "\n",
      "===== Threshold = 0.3 =====\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.33      0.48    422243\n",
      "           1       0.32      0.90      0.47    146544\n",
      "\n",
      "    accuracy                           0.47    568787\n",
      "   macro avg       0.61      0.61      0.47    568787\n",
      "weighted avg       0.75      0.47      0.48    568787\n",
      "\n",
      "\n",
      "===== Threshold = 0.35 =====\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.40      0.55    422243\n",
      "           1       0.33      0.86      0.48    146544\n",
      "\n",
      "    accuracy                           0.52    568787\n",
      "   macro avg       0.61      0.63      0.52    568787\n",
      "weighted avg       0.75      0.52      0.53    568787\n",
      "\n",
      "\n",
      "===== Threshold = 0.4 =====\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.48      0.62    422243\n",
      "           1       0.35      0.80      0.48    146544\n",
      "\n",
      "    accuracy                           0.56    568787\n",
      "   macro avg       0.61      0.64      0.55    568787\n",
      "weighted avg       0.74      0.56      0.58    568787\n",
      "\n",
      "\n",
      "===== Threshold = 0.45 =====\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.55      0.67    422243\n",
      "           1       0.36      0.73      0.48    146544\n",
      "\n",
      "    accuracy                           0.60    568787\n",
      "   macro avg       0.61      0.64      0.58    568787\n",
      "weighted avg       0.73      0.60      0.62    568787\n",
      "\n",
      "\n",
      "===== Threshold = 0.5 =====\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.63      0.72    422243\n",
      "           1       0.38      0.65      0.48    146544\n",
      "\n",
      "    accuracy                           0.64    568787\n",
      "   macro avg       0.61      0.64      0.60    568787\n",
      "weighted avg       0.72      0.64      0.66    568787\n",
      "\n",
      "ROC-AUC: 0.703939393953028\n",
      "PR-AUC : 0.4533523684695588\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import classification_report, roc_auc_score, average_precision_score\n",
    "\n",
    "# =====================================================\n",
    "# 1Ô∏è‚É£ Îç∞Ïù¥ÌÑ∞ Î°úÎìú + ÏãúÍ∞Ñ ÌååÏÉù\n",
    "# =====================================================\n",
    "df = pd.read_csv(\"new_flight_weather_merged.csv\")\n",
    "\n",
    "df[\"departure_datetime\"] = pd.to_datetime(df[\"departure_datetime\"])\n",
    "df[\"dep_hour\"] = df[\"departure_datetime\"].dt.hour\n",
    "df[\"dep_weekday\"] = df[\"departure_datetime\"].dt.weekday\n",
    "df[\"is_weekend\"] = df[\"dep_weekday\"].isin([5, 6]).astype(int)\n",
    "\n",
    "print(\"Ï†ÑÏ≤¥ Îç∞Ïù¥ÌÑ∞ Ïàò:\", len(df))\n",
    "\n",
    "# =====================================================\n",
    "# 2Ô∏è‚É£ Ïª¨Îüº Ï†ïÏùò\n",
    "# =====================================================\n",
    "num_cols = [\"Í∏∞Ïò®(¬∞C)\", \"ÌíçÏÜç_ms\", \"dep_hour\", \"dep_weekday\", \"is_weekend\"]\n",
    "num_cols = [c for c in num_cols if c in df.columns]\n",
    "\n",
    "cat_cols = [\"Í≥µÌï≠Î™Ö\", \"Ï∂úÎ∞úÏßÄ\", \"ÎèÑÏ∞©ÏßÄ\", \"flight_type\"]\n",
    "cat_cols = [c for c in cat_cols if c in df.columns]\n",
    "\n",
    "# LightGBMÏö© category Î≥ÄÌôò\n",
    "for c in cat_cols:\n",
    "    df[c] = df[c].astype(\"category\")\n",
    "\n",
    "X_cols = num_cols + cat_cols\n",
    "\n",
    "# =====================================================\n",
    "# 3Ô∏è‚É£ Train / Test Î∂ÑÎ¶¨ (ÏãúÍ∞Ñ Í∏∞Ï§Ä)\n",
    "# =====================================================\n",
    "df = df.sort_values(\"departure_datetime\")\n",
    "split_date = df[\"departure_datetime\"].quantile(0.8)\n",
    "\n",
    "train_df = df[df[\"departure_datetime\"] <= split_date]\n",
    "test_df  = df[df[\"departure_datetime\"] > split_date]\n",
    "\n",
    "print(\"Train:\", len(train_df), \"Test:\", len(test_df))\n",
    "\n",
    "# =====================================================\n",
    "# 4Ô∏è‚É£ üî• Îã§Ïö¥ÏÇ¨Ïù¥Ïßï (Train Îç∞Ïù¥ÌÑ∞Îßå)\n",
    "# =====================================================\n",
    "train_0 = train_df[train_df[\"is_delay\"] == 0]\n",
    "train_1 = train_df[train_df[\"is_delay\"] == 1]\n",
    "\n",
    "print(\"Before Downsampling\")\n",
    "print(\"Ï†ïÏÉÅ(0):\", len(train_0), \"ÏßÄÏó∞(1):\", len(train_1))\n",
    "\n",
    "# üëâ Ï†ïÏÉÅ(0)ÏùÑ ÏßÄÏó∞(1) Í∞úÏàòÎßåÌÅº ÎûúÎç§ ÏÉòÌîåÎßÅ\n",
    "train_0_down = train_0.sample(\n",
    "    n=len(train_1),\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "train_down = (\n",
    "    pd.concat([train_0_down, train_1])\n",
    "    .sample(frac=1, random_state=42)\n",
    ")\n",
    "\n",
    "print(\"After Downsampling\")\n",
    "print(train_down[\"is_delay\"].value_counts())\n",
    "\n",
    "# =====================================================\n",
    "# 5Ô∏è‚É£ X / y Î∂ÑÎ¶¨\n",
    "# =====================================================\n",
    "X_train = train_down[X_cols]\n",
    "y_train = train_down[\"is_delay\"]\n",
    "\n",
    "X_test  = test_df[X_cols]\n",
    "y_test  = test_df[\"is_delay\"]\n",
    "\n",
    "# =====================================================\n",
    "# 6Ô∏è‚É£ LightGBM Î™®Îç∏ (‚ùå class_weight Ï†úÍ±∞)\n",
    "# =====================================================\n",
    "lgbm = LGBMClassifier(\n",
    "    n_estimators=500,\n",
    "    learning_rate=0.05,\n",
    "    num_leaves=64,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "\n",
    "    objective=\"binary\",\n",
    "    metric=\"aucpr\",\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# categorical_feature ÏßÄÏ†ï\n",
    "lgbm.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    categorical_feature=cat_cols\n",
    ")\n",
    "\n",
    "print(\"‚úÖ LightGBM (Downsampling) ÌïôÏäµ ÏôÑÎ£å\")\n",
    "\n",
    "# =====================================================\n",
    "# 7Ô∏è‚É£ ÌèâÍ∞Ä\n",
    "# =====================================================\n",
    "y_prob = lgbm.predict_proba(X_test)[:, 1]\n",
    "\n",
    "for t in [0.3, 0.35, 0.4, 0.45, 0.5]:\n",
    "    print(f\"\\n===== Threshold = {t} =====\")\n",
    "    y_pred = (y_prob >= t).astype(int)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, y_prob))\n",
    "print(\"PR-AUC :\", average_precision_score(y_test, y_prob))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c3c959",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä ÏãúÍ∞ÅÌôî: ÏÑ±Îä• ÏöîÏïΩ Ìëú & Í∑∏ÎûòÌîÑ\n",
    "\n",
    "ÏïÑÎûò ÏÖÄÎì§ÏùÄ **Í∏∞Ï°¥ ÏΩîÎìú(ÌïôÏäµ/ÏòàÏ∏°/ÌèâÍ∞Ä)** Ïã§ÌñâÏù¥ ÎÅùÎÇú Îí§, Îß® ÏïÑÎûòÏóêÏÑú Ï∂îÍ∞ÄÎ°ú Ïã§ÌñâÌïòÎ©¥ Îê©ÎãàÎã§.  \n",
    "(Í∏∞Ï°¥ ÏΩîÎìúÎäî Í∑∏ÎåÄÎ°ú Ïú†ÏßÄÌñàÍ≥†, ÏãúÍ∞ÅÌôîÎßå \"Ï∂îÍ∞Ä\"ÌñàÏäµÎãàÎã§.)\n"
   ],
   "id": "401d2021"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# =====================================================\n",
    "# üìå ÏãúÍ∞ÅÌôî Ï§ÄÎπÑ: Î≥ÄÏàò ÏûêÎèô ÌÉêÏÉâ + Í∏∞Î≥∏ ÏÑ±Îä• ÏöîÏïΩ Ìëú ÏÉùÏÑ±\n",
    "# -----------------------------------------------------\n",
    "# ‚úÖ Ïù¥ ÏÖÄÏùÄ \"Í∏∞Ï°¥ ÏΩîÎìú\"ÏóêÏÑú ÎßåÎì† Î≥ÄÏàòÎì§ÏùÑ ÏµúÎåÄÌïú ÏûêÎèôÏúºÎ°ú Ï∞æÏïÑÏÑú,\n",
    "#    - y_true (Ï†ïÎãµ)\n",
    "#    - y_proba (ÏòàÏ∏° ÌôïÎ•†)\n",
    "#    - y_pred (ÏòàÏ∏° ÎùºÎ≤®)\n",
    "#    - model (ÌïôÏäµ Î™®Îç∏)\n",
    "#    - X_test (ÌÖåÏä§Ìä∏ ÎèÖÎ¶ΩÎ≥ÄÏàò)\n",
    "# Î•º ÌôïÎ≥¥Ìïú Îí§, ÌëúÎ°ú Ï†ïÎ¶¨Ìï©ÎãàÎã§.\n",
    "#\n",
    "# ‚ö†Ô∏è ÎÖ∏Ìä∏Î∂ÅÎßàÎã§ Î≥ÄÏàòÎ™ÖÏù¥ Ï°∞Í∏àÏî© Îã§Î•º Ïàò ÏûàÏñ¥ÏÑú,\n",
    "#    ÏïÑÎûò ÏΩîÎìúÍ∞Ä Ïó¨Îü¨ ÌõÑÎ≥¥ Ïù¥Î¶ÑÏùÑ ÏàúÏÑúÎåÄÎ°ú ÌÉêÏÉâÌï©ÎãàÎã§.\n",
    "# =====================================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    average_precision_score\n",
    ")\n",
    "\n",
    "def _pick_first_existing(name_candidates):\n",
    "    # Ïó¨Îü¨ Î≥ÄÏàòÎ™Ö ÌõÑÎ≥¥ Ï§ëÏóêÏÑú ÌòÑÏû¨ ÎÖ∏Ìä∏Î∂Å Ïã§Ìñâ ÌôòÍ≤Ω(globals)Ïóê Ï°¥Ïû¨ÌïòÎäî\n",
    "    # 'Ï≤´ Î≤àÏß∏' Î≥ÄÏàòÎ•º Ï∞æÏïÑ (Í∞í, Î≥ÄÏàòÎ™Ö) ÌòïÌÉúÎ°ú Î∞òÌôò\n",
    "    for n in name_candidates:\n",
    "        if n in globals():\n",
    "            return globals()[n], n\n",
    "    return None, None\n",
    "\n",
    "def _as_1d_array(x):\n",
    "    # Î¶¨Ïä§Ìä∏/ÏãúÎ¶¨Ï¶à/ÎÑòÌååÏù¥ Îì± -> 1Ï∞®Ïõê np.arrayÎ°ú ÏïàÏ†ÑÌïòÍ≤å Î≥ÄÌôò\n",
    "    if x is None:\n",
    "        return None\n",
    "    try:\n",
    "        arr = np.array(x)\n",
    "        # (N,1) ÎòêÎäî (1,N) Í∞ôÏùÄ ÌòïÌÉúÎ©¥ 1Ï∞®ÏõêÏúºÎ°ú ÌéºÏπ®\n",
    "        return arr.reshape(-1)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 1) y_true(Ï†ïÎãµ) ÏûêÎèô ÌÉêÏÉâ\n",
    "# -----------------------------------------------------\n",
    "y_true, y_true_name = _pick_first_existing([\n",
    "    \"y_test\", \"test_y\", \"y_valid\", \"y_val\", \"y_true\", \"Y_test\", \"Y_val\"\n",
    "])\n",
    "y_true = _as_1d_array(y_true)\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 2) X_test(ÌÖåÏä§Ìä∏ ÎèÖÎ¶ΩÎ≥ÄÏàò) ÏûêÎèô ÌÉêÏÉâ (ÌîºÏ≤òÎ™Ö Ï∂îÏ∂úÏö©)\n",
    "# -----------------------------------------------------\n",
    "X_test, X_test_name = _pick_first_existing([\n",
    "    \"X_test\", \"test_X\", \"X_valid\", \"X_val\", \"X_te\", \"x_test\"\n",
    "])\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 3) model(ÌïôÏäµ Î™®Îç∏) ÏûêÎèô ÌÉêÏÉâ\n",
    "# -----------------------------------------------------\n",
    "# ‚úÖ ÎπÑÍµê ÎÖ∏Ìä∏Î∂Å(Ïó¨Îü¨ Î™®Îç∏)ÎèÑ ÏûàÏùÑ Ïàò ÏûàÏñ¥ÏÑú, ÌùîÌïú Ïù¥Î¶ÑÎì§ÏùÑ ÎÑìÍ≤å ÌÉêÏÉâÌï©ÎãàÎã§.\n",
    "model, model_name = _pick_first_existing([\n",
    "    \"model\", \"clf\", \"classifier\",\n",
    "    \"lgb_model\", \"lgbm_model\", \"lgbm\",\n",
    "    \"xgb_model\", \"xgb\", \"xgb_clf\",\n",
    "    \"best_model\", \"final_model\"\n",
    "])\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 4) y_proba(ÏòàÏ∏° ÌôïÎ•†) ÏûêÎèô ÌÉêÏÉâ\n",
    "# -----------------------------------------------------\n",
    "# ‚úÖ Ïù¥ÎØ∏ ÎßåÎì§Ïñ¥Îëî ÌôïÎ•† Î≥ÄÏàòÍ∞Ä ÏûàÏúºÎ©¥ Í∑∏Í±∏ Ïö∞ÏÑ† ÏÇ¨Ïö©Ìï©ÎãàÎã§.\n",
    "y_proba, y_proba_name = _pick_first_existing([\n",
    "    \"y_proba\", \"y_pred_proba\", \"pred_proba\", \"proba\",\n",
    "    \"y_score\", \"scores\", \"prob\", \"p_pred\"\n",
    "])\n",
    "\n",
    "# ‚úÖ ÌôïÎ•† Î≥ÄÏàòÍ∞Ä ÏóÜÏúºÎ©¥, model + X_testÎ°ú ÏßÅÏ†ë Í≥ÑÏÇ∞ÏùÑ ÏãúÎèÑÌï©ÎãàÎã§.\n",
    "if y_proba is None and model is not None and X_test is not None:\n",
    "    try:\n",
    "        # sklearn / xgboost / lightgbm ÎåÄÎ∂ÄÎ∂ÑÏùÄ predict_proba ÏßÄÏõê\n",
    "        if hasattr(model, \"predict_proba\"):\n",
    "            proba = model.predict_proba(X_test)\n",
    "            # Î≥¥ÌÜµ Ïù¥ÏßÑÎ∂ÑÎ•òÎäî (N, 2) -> positive class ÌôïÎ•†ÏùÄ [:, 1]\n",
    "            if isinstance(proba, np.ndarray) and proba.ndim == 2 and proba.shape[1] >= 2:\n",
    "                y_proba = proba[:, 1]\n",
    "                y_proba_name = f\"{model_name}.predict_proba({X_test_name})[:,1]\"\n",
    "            else:\n",
    "                # ÌòπÏãú (N,)ÏúºÎ°ú Î∞îÎ°ú ÎÇòÏò§Îäî Í≤ΩÏö∞\n",
    "                y_proba = proba\n",
    "                y_proba_name = f\"{model_name}.predict_proba({X_test_name})\"\n",
    "        # decision_functionÎßå ÏûàÎäî Î™®Îç∏ÎèÑ Ï°¥Ïû¨Ìï† Ïàò ÏûàÏùå (SVM Îì±)\n",
    "        elif hasattr(model, \"decision_function\"):\n",
    "            score = model.decision_function(X_test)\n",
    "            y_proba = score\n",
    "            y_proba_name = f\"{model_name}.decision_function({X_test_name})\"\n",
    "    except Exception as e:\n",
    "        print(\"‚ö†Ô∏è modelÎ°úÎ∂ÄÌÑ∞ ÏòàÏ∏° ÌôïÎ•†(y_proba) Í≥ÑÏÇ∞ Ïã§Ìå®:\", repr(e))\n",
    "\n",
    "y_proba = _as_1d_array(y_proba)\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 5) y_pred(ÏòàÏ∏° ÎùºÎ≤®) ÏûêÎèô ÌÉêÏÉâ\n",
    "# -----------------------------------------------------\n",
    "y_pred, y_pred_name = _pick_first_existing([\n",
    "    \"y_pred\", \"pred\", \"y_hat\", \"y_pred_label\"\n",
    "])\n",
    "\n",
    "# ‚úÖ y_predÍ∞Ä ÏóÜÏúºÎ©¥, y_probaÎ°ú threshold=0.5 Í∏∞Ï§Ä ÎùºÎ≤® ÏÉùÏÑ±\n",
    "if y_pred is None and y_proba is not None:\n",
    "    y_pred = (y_proba >= 0.5).astype(int)\n",
    "    y_pred_name = \"derived_from_y_proba(threshold=0.5)\"\n",
    "\n",
    "y_pred = _as_1d_array(y_pred)\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 6) ÌôïÎ≥¥Ìïú Î≥ÄÏàòÎì§ ÏöîÏïΩ Ï∂úÎ†•\n",
    "# -----------------------------------------------------\n",
    "print(\"‚úÖ [ÏûêÎèô ÌÉêÏÉâ Í≤∞Í≥º]\")\n",
    "print(f\" - y_true  : {y_true_name}\")\n",
    "print(f\" - y_proba : {y_proba_name}\")\n",
    "print(f\" - y_pred  : {y_pred_name}\")\n",
    "print(f\" - model   : {model_name}\")\n",
    "print(f\" - X_test  : {X_test_name}\")\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 7) Í∏∞Î≥∏ ÏÑ±Îä• ÏöîÏïΩ Ìëú(Ïù¥ÏßÑÎ∂ÑÎ•ò Í∏∞Ï§Ä)\n",
    "# -----------------------------------------------------\n",
    "# ‚ö†Ô∏è y_true ÎòêÎäî y_predÍ∞Ä ÏóÜÏúºÎ©¥ ÌëúÎ•º ÎßåÎì§ Ïàò ÏóÜÏúºÎãà ÏïàÎÇ¥ ÌõÑ Ï¢ÖÎ£åÌï©ÎãàÎã§.\n",
    "if y_true is None or y_pred is None:\n",
    "    raise ValueError(\"y_true ÎòêÎäî y_predÎ•º Ï∞æÏßÄ Î™ªÌñàÏäµÎãàÎã§. (Í∏∞Ï°¥ ÏΩîÎìúÏóêÏÑú test Ï†ïÎãµ/ÏòàÏ∏° Î≥ÄÏàòÎ•º ÎßåÎì† Îí§ Îã§Ïãú Ïã§ÌñâÌïòÏÑ∏Ïöî.)\")\n",
    "\n",
    "# ‚úÖ classification_reportÎ•º DataFrameÏúºÎ°ú Î≥ÄÌôò (ÌëúÎ°ú Î≥¥Í∏∞ Ï¢ãÍ≤å)\n",
    "report_dict = classification_report(y_true, y_pred, output_dict=True, zero_division=0)\n",
    "report_df = pd.DataFrame(report_dict).T\n",
    "\n",
    "# ‚úÖ Ï†ÑÏ≤¥ Ïä§ÏπºÎùº ÏßÄÌëú(ÏûàÏùÑ ÎïåÎßå Í≥ÑÏÇ∞)\n",
    "metrics = {\n",
    "    \"accuracy\": accuracy_score(y_true, y_pred),\n",
    "    \"precision(binary)\": precision_score(y_true, y_pred, zero_division=0),\n",
    "    \"recall(binary)\": recall_score(y_true, y_pred, zero_division=0),\n",
    "    \"f1(binary)\": f1_score(y_true, y_pred, zero_division=0),\n",
    "}\n",
    "\n",
    "# ‚úÖ ÌôïÎ•†Ïù¥ ÏûàÏúºÎ©¥ ROC-AUC / PR-AUCÎèÑ Í≥ÑÏÇ∞\n",
    "if y_proba is not None:\n",
    "    try:\n",
    "        metrics[\"roc_auc\"] = roc_auc_score(y_true, y_proba)\n",
    "    except Exception:\n",
    "        metrics[\"roc_auc\"] = np.nan\n",
    "    try:\n",
    "        metrics[\"pr_auc(AP)\"] = average_precision_score(y_true, y_proba)\n",
    "    except Exception:\n",
    "        metrics[\"pr_auc(AP)\"] = np.nan\n",
    "else:\n",
    "    metrics[\"roc_auc\"] = np.nan\n",
    "    metrics[\"pr_auc(AP)\"] = np.nan\n",
    "\n",
    "metrics_df = pd.DataFrame([metrics])\n",
    "\n",
    "print(\"\\n‚úÖ [ÏÑ±Îä• ÏöîÏïΩ(Ïä§ÏπºÎùº)]\")\n",
    "display(metrics_df)\n",
    "\n",
    "print(\"\\n‚úÖ [Classification Report (Ìëú)]\")\n",
    "display(report_df)\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 8) Confusion Matrix(ÌòºÎèôÌñâÎ†¨) Ìëú\n",
    "# -----------------------------------------------------\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "cm_df = pd.DataFrame(cm, index=[\"Actual 0\", \"Actual 1\"], columns=[\"Pred 0\", \"Pred 1\"])\n",
    "\n",
    "print(\"\\n‚úÖ [Confusion Matrix (Ìëú)]\")\n",
    "display(cm_df)\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 9) Threshold(ÏûÑÍ≥ÑÍ∞í) Ïä§Ïúï ÌÖåÏù¥Î∏î\n",
    "# -----------------------------------------------------\n",
    "# ‚úÖ ÌôïÎ•†(y_proba)Ïù¥ ÏûàÏùÑ ÎïåÎßå ÏùòÎØ∏Í∞Ä ÏûàÏúºÎØÄÎ°ú, ÏóÜÏúºÎ©¥ Ïä§ÌÇµÌï©ÎãàÎã§.\n",
    "if y_proba is not None:\n",
    "    thresholds = np.linspace(0.05, 0.95, 19)\n",
    "    rows = []\n",
    "    for t in thresholds:\n",
    "        yp = (y_proba >= t).astype(int)\n",
    "        rows.append({\n",
    "            \"threshold\": float(np.round(t, 2)),\n",
    "            \"accuracy\": accuracy_score(y_true, yp),\n",
    "            \"precision\": precision_score(y_true, yp, zero_division=0),\n",
    "            \"recall\": recall_score(y_true, yp, zero_division=0),\n",
    "            \"f1\": f1_score(y_true, yp, zero_division=0),\n",
    "        })\n",
    "    thr_df = pd.DataFrame(rows).sort_values(\"threshold\")\n",
    "    print(\"\\n‚úÖ [Threshold Ïä§Ïúï ÏÑ±Îä• Ìëú] (ÌôïÎ•† Í∏∞Î∞ò)\")\n",
    "    display(thr_df)\n",
    "else:\n",
    "    thr_df = None\n",
    "    print(\"\\n‚ÑπÔ∏è y_proba(ÏòàÏ∏° ÌôïÎ•†)Í∞Ä ÏóÜÏñ¥ threshold Ïä§Ïúï ÌëúÎäî ÏÉùÎûµÌï©ÎãàÎã§.\")\n"
   ],
   "outputs": [],
   "execution_count": null,
   "id": "978522f6"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# =====================================================\n",
    "# üìà ÏãúÍ∞ÅÌôî: ÌòºÎèôÌñâÎ†¨ / ROC / PR / ÌôïÎ•†Î∂ÑÌè¨ / ÏûÑÍ≥ÑÍ∞í Í≥°ÏÑ† / Ï§ëÏöî ÌîºÏ≤ò\n",
    "# -----------------------------------------------------\n",
    "# ‚úÖ Ïù¥ ÏÖÄÏùÄ ÏúÑ ÏÖÄÏóêÏÑú ÎßåÎì†(ÎòêÎäî Ï∞æÏùÄ) Î≥ÄÏàò(y_true, y_pred, y_proba, model, X_test)Î•º ÏÇ¨Ïö©Ìï©ÎãàÎã§.\n",
    "# ‚úÖ Í∑∏ÎûòÌîÑÎäî matplotlib Í∏∞Î≥∏ Ïä§ÌÉÄÏùº(ÏÉâ ÏßÄÏ†ï ÏóÜÏùå)Î°ú Í∑∏Î¶ΩÎãàÎã§.\n",
    "# =====================================================\n",
    "\n",
    "from sklearn.metrics import roc_curve, precision_recall_curve\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 1) ÌòºÎèôÌñâÎ†¨(Confusion Matrix) ÏãúÍ∞ÅÌôî\n",
    "# -----------------------------------------------------\n",
    "plt.figure(figsize=(5, 4))\n",
    "plt.imshow(cm, interpolation=\"nearest\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.colorbar()\n",
    "\n",
    "tick_marks = np.arange(2)\n",
    "plt.xticks(tick_marks, [\"Pred 0\", \"Pred 1\"])\n",
    "plt.yticks(tick_marks, [\"Actual 0\", \"Actual 1\"])\n",
    "\n",
    "# ‚úÖ ÏÖÄ ÏïàÏóê Ïà´Ïûê(Í±¥Ïàò) ÌëúÏãú\n",
    "for i in range(cm.shape[0]):\n",
    "    for j in range(cm.shape[1]):\n",
    "        plt.text(j, i, str(cm[i, j]), ha=\"center\", va=\"center\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 2) ROC Curve (ÌôïÎ•†Ïù¥ ÏûàÏùÑ ÎïåÎßå)\n",
    "# -----------------------------------------------------\n",
    "if y_proba is not None:\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_proba)\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.plot(fpr, tpr, label=\"ROC\")\n",
    "    plt.plot([0, 1], [0, 1], linestyle=\"--\", label=\"Random\")\n",
    "    plt.title(\"ROC Curve\")\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 3) Precision-Recall Curve (ÌôïÎ•†Ïù¥ ÏûàÏùÑ ÎïåÎßå)\n",
    "# -----------------------------------------------------\n",
    "if y_proba is not None:\n",
    "    precision, recall, _ = precision_recall_curve(y_true, y_proba)\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.plot(recall, precision, label=\"PR\")\n",
    "    plt.title(\"Precision-Recall Curve\")\n",
    "    plt.xlabel(\"Recall\")\n",
    "    plt.ylabel(\"Precision\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 4) ÏòàÏ∏° ÌôïÎ•† Î∂ÑÌè¨(ÌÅ¥ÎûòÏä§Î≥Ñ) (ÌôïÎ•†Ïù¥ ÏûàÏùÑ ÎïåÎßå)\n",
    "# -----------------------------------------------------\n",
    "# ‚úÖ ÌÅ¥ÎûòÏä§ 0Í≥º 1Ïùò ÏòàÏ∏° ÌôïÎ•† Î∂ÑÌè¨Î•º Îî∞Î°ú Í∑∏Î¶¨Î©¥,\n",
    "#    Î™®Îç∏Ïù¥ Ïñ¥Îäê Ï†ïÎèÑÎ°ú Îëê ÌÅ¥ÎûòÏä§Î•º \"Î∂ÑÎ¶¨\"ÌïòÎäîÏßÄ ÏßÅÍ¥ÄÏ†ÅÏúºÎ°ú ÌôïÏù∏ Í∞ÄÎä•Ìï©ÎãàÎã§.\n",
    "if y_proba is not None:\n",
    "    y_proba_0 = y_proba[y_true == 0]\n",
    "    y_proba_1 = y_proba[y_true == 1]\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.hist(y_proba_0, bins=50, alpha=0.6, label=\"Actual 0\")\n",
    "    plt.hist(y_proba_1, bins=50, alpha=0.6, label=\"Actual 1\")\n",
    "    plt.title(\"Predicted Probability Distribution\")\n",
    "    plt.xlabel(\"Predicted probability (positive class)\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 5) Threshold(ÏûÑÍ≥ÑÍ∞í) Î≥ÄÌôîÏóê Îî∞Î•∏ Precision/Recall/F1 Í≥°ÏÑ† (ÌôïÎ•†Ïù¥ ÏûàÏùÑ ÎïåÎßå)\n",
    "# -----------------------------------------------------\n",
    "if thr_df is not None:\n",
    "    plt.figure(figsize=(7, 4))\n",
    "    plt.plot(thr_df[\"threshold\"], thr_df[\"precision\"], label=\"precision\")\n",
    "    plt.plot(thr_df[\"threshold\"], thr_df[\"recall\"], label=\"recall\")\n",
    "    plt.plot(thr_df[\"threshold\"], thr_df[\"f1\"], label=\"f1\")\n",
    "    plt.title(\"Precision / Recall / F1 vs Threshold\")\n",
    "    plt.xlabel(\"Threshold\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 6) Ï§ëÏöî ÌîºÏ≤ò(Feature Importance / Coef) Top 20\n",
    "# -----------------------------------------------------\n",
    "# ‚úÖ Ìä∏Î¶¨ Í∏∞Î∞ò Î™®Îç∏(lightgbm/xgboost Îì±): feature_importances_\n",
    "# ‚úÖ ÏÑ†Ìòï Î™®Îç∏(logistic regression Îì±): coef_\n",
    "#\n",
    "# ‚ö†Ô∏è ÌîºÏ≤òÎ™ÖÏù¥ ÌïÑÏöîÌï©ÎãàÎã§. Î≥¥ÌÜµ X_testÍ∞Ä DataFrameÏù¥Î©¥ columnsÎ°ú Í∞ÄÏ†∏ÏòµÎãàÎã§.\n",
    "#    (numpy arrayÏù¥Î©¥, ÌîºÏ≤òÎ™ÖÏùÑ Î™®Î•º Ïàò ÏûàÏñ¥ indexÎ°ú ÌëúÏãúÌï©ÎãàÎã§.)\n",
    "# -----------------------------------------------------\n",
    "feature_names = None\n",
    "if X_test is not None:\n",
    "    try:\n",
    "        if hasattr(X_test, \"columns\"):\n",
    "            feature_names = list(X_test.columns)\n",
    "        else:\n",
    "            # numpy arrayÏù∏ Í≤ΩÏö∞: ÌîºÏ≤òÎ™Ö ÏóÜÏùå -> Î≤àÌò∏Î°ú ÎåÄÏ≤¥\n",
    "            feature_names = [f\"f{i}\" for i in range(X_test.shape[1])]\n",
    "    except Exception:\n",
    "        feature_names = None\n",
    "\n",
    "def _plot_top_features(values, names, title, top_n=20):\n",
    "    # Ï§ëÏöîÎèÑ/Í≥ÑÏàò Î∞∞Ïó¥(values)ÏôÄ ÌîºÏ≤òÎ™Ö(names)ÏúºÎ°ú Top-N ÎßâÎåÄÍ∑∏ÎûòÌîÑÎ•º Í∑∏Î¶ΩÎãàÎã§.\n",
    "    # - values: (num_features,) ÌòïÌÉú\n",
    "    # - names : Í∏∏Ïù¥ num_features\n",
    "    s = pd.Series(values, index=names)\n",
    "    # Ï†àÎåÄÍ∞í Í∏∞Ï§Ä Top-N (Ïñë/Ïùå Î™®Îëê Ï§ëÏöîÌï† Ïàò ÏûàÏñ¥ÏÑú)\n",
    "    top = s.reindex(s.abs().sort_values(ascending=False).index).head(top_n)\n",
    "    top = top.iloc[::-1]  # Î≥¥Í∏∞ Ï¢ãÍ≤å Ïó≠Ïàú\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.barh(top.index, top.values)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Importance / Coefficient\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# ‚úÖ modelÏù¥ Ï°¥Ïû¨ÌïòÍ≥†, feature_namesÍ∞Ä ÏûàÏùÑ ÎïåÎßå ÏãúÍ∞ÅÌôî ÏãúÎèÑ\n",
    "if model is not None and feature_names is not None:\n",
    "    try:\n",
    "        # 6-A) Ìä∏Î¶¨ Í∏∞Î∞ò importance\n",
    "        if hasattr(model, \"feature_importances_\"):\n",
    "            imp = np.array(model.feature_importances_).reshape(-1)\n",
    "            if len(imp) == len(feature_names):\n",
    "                _plot_top_features(imp, feature_names, \"Top Features (feature_importances_)\")\n",
    "            else:\n",
    "                print(\"‚ö†Ô∏è feature_importances_ Í∏∏Ïù¥ÏôÄ feature_names Í∏∏Ïù¥Í∞Ä Îã¨Îùº importance ÏãúÍ∞ÅÌôîÎ•º ÏÉùÎûµÌï©ÎãàÎã§.\")\n",
    "        # 6-B) ÏÑ†Ìòï Î™®Îç∏ coef\n",
    "        elif hasattr(model, \"coef_\"):\n",
    "            coef = np.array(model.coef_).reshape(-1)\n",
    "            if len(coef) == len(feature_names):\n",
    "                _plot_top_features(coef, feature_names, \"Top Features (coef_)\")\n",
    "            else:\n",
    "                print(\"‚ö†Ô∏è coef_ Í∏∏Ïù¥ÏôÄ feature_names Í∏∏Ïù¥Í∞Ä Îã¨Îùº coef ÏãúÍ∞ÅÌôîÎ•º ÏÉùÎûµÌï©ÎãàÎã§.\")\n",
    "        else:\n",
    "            print(\"‚ÑπÔ∏è Ïù¥ Î™®Îç∏ÏùÄ feature_importances_ ÎòêÎäî coef_Í∞Ä ÏóÜÏñ¥ Ï§ëÏöî ÌîºÏ≤ò ÏãúÍ∞ÅÌôîÎ•º ÏÉùÎûµÌï©ÎãàÎã§.\")\n",
    "    except Exception as e:\n",
    "        print(\"‚ö†Ô∏è Ï§ëÏöî ÌîºÏ≤ò ÏãúÍ∞ÅÌôî Ï§ë Ïò§Î•ò:\", repr(e))\n",
    "else:\n",
    "    print(\"‚ÑπÔ∏è model ÎòêÎäî feature_namesÎ•º ÌôïÎ≥¥ÌïòÏßÄ Î™ªÌï¥ Ï§ëÏöî ÌîºÏ≤ò ÏãúÍ∞ÅÌôîÎ•º ÏÉùÎûµÌï©ÎãàÎã§.\")\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 7) (ÏòµÏÖò) Ïó¨Îü¨ Î™®Îç∏ ÎπÑÍµêÍ∞Ä Í∞ÄÎä•Ìïú Í≤ΩÏö∞: models(dict)Í∞Ä ÏûàÏúºÎ©¥ ÏÑ±Îä•Ìëú ÏÉùÏÑ±\n",
    "# -----------------------------------------------------\n",
    "# ‚úÖ ÎπÑÍµê ÎÖ∏Ìä∏Î∂ÅÏóêÏÑú models = {\"lgb\":..., \"xgb\":..., ...} ÌòïÌÉúÎ°ú Í∞ÄÏßÄÍ≥† ÏûàÎäî Í≤ΩÏö∞Í∞Ä ÏûàÏñ¥ÏÑú\n",
    "#    ÏûàÏúºÎ©¥ ÏûêÎèôÏúºÎ°ú ÎèåÎ†§ÏÑú ÌëúÎ•º ÎßåÎì§Ïñ¥ Ï§çÎãàÎã§.\n",
    "# -----------------------------------------------------\n",
    "models_dict = globals().get(\"models\", None)\n",
    "\n",
    "if isinstance(models_dict, dict) and X_test is not None and y_true is not None:\n",
    "    rows = []\n",
    "    for k, m in models_dict.items():\n",
    "        try:\n",
    "            # ÏòàÏ∏° ÌôïÎ•† Í≥ÑÏÇ∞\n",
    "            if hasattr(m, \"predict_proba\"):\n",
    "                p = m.predict_proba(X_test)\n",
    "                if isinstance(p, np.ndarray) and p.ndim == 2 and p.shape[1] >= 2:\n",
    "                    p = p[:, 1]\n",
    "            elif hasattr(m, \"decision_function\"):\n",
    "                p = m.decision_function(X_test)\n",
    "            else:\n",
    "                p = None\n",
    "\n",
    "            # ÏòàÏ∏° ÎùºÎ≤®(Í∏∞Î≥∏ threshold=0.5)\n",
    "            if p is not None:\n",
    "                yp = (np.array(p).reshape(-1) >= 0.5).astype(int)\n",
    "                roc = roc_auc_score(y_true, p)\n",
    "                pr = average_precision_score(y_true, p)\n",
    "            else:\n",
    "                yp = m.predict(X_test)\n",
    "                roc = np.nan\n",
    "                pr = np.nan\n",
    "\n",
    "            rows.append({\n",
    "                \"model_name\": k,\n",
    "                \"accuracy\": accuracy_score(y_true, yp),\n",
    "                \"precision\": precision_score(y_true, yp, zero_division=0),\n",
    "                \"recall\": recall_score(y_true, yp, zero_division=0),\n",
    "                \"f1\": f1_score(y_true, yp, zero_division=0),\n",
    "                \"roc_auc\": roc,\n",
    "                \"pr_auc(AP)\": pr\n",
    "            })\n",
    "        except Exception as e:\n",
    "            rows.append({\"model_name\": k, \"error\": repr(e)})\n",
    "\n",
    "    compare_df = pd.DataFrame(rows)\n",
    "    print(\"\\n‚úÖ [Ïó¨Îü¨ Î™®Îç∏ ÎπÑÍµê ÏÑ±Îä•Ìëú]\")\n",
    "    display(compare_df)\n"
   ],
   "outputs": [],
   "execution_count": null,
   "id": "06fc80d9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "4vector(ipykernel)",
   "language": "python",
   "name": "4vector"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}