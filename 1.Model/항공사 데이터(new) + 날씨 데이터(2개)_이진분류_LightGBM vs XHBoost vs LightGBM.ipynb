{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc7d6299",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-21T08:28:15.032570Z",
     "start_time": "2026-01-21T08:27:57.371718Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_12984\\4191327705.py:13: DtypeWarning: Columns (28,49) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"new_flight_weather_merged.csv\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ CSV Î°úÎìú: 2843934\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    roc_auc_score,\n",
    "    average_precision_score\n",
    ")\n",
    "\n",
    "# =========================\n",
    "# Îç∞Ïù¥ÌÑ∞ Î°úÎìú\n",
    "# =========================\n",
    "df = pd.read_csv(\"new_flight_weather_merged.csv\")\n",
    "print(\"‚úÖ CSV Î°úÎìú:\", len(df))\n",
    "\n",
    "# =========================\n",
    "# ÏãúÍ∞Ñ ÌååÏÉù Î≥ÄÏàò\n",
    "# =========================\n",
    "df[\"departure_datetime\"] = pd.to_datetime(df[\"departure_datetime\"])\n",
    "\n",
    "df[\"dep_hour\"] = df[\"departure_datetime\"].dt.hour\n",
    "df[\"dep_weekday\"] = df[\"departure_datetime\"].dt.weekday\n",
    "df[\"is_weekend\"] = df[\"dep_weekday\"].isin([5, 6]).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c30de288",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-21T08:28:15.047627Z",
     "start_time": "2026-01-21T08:28:15.033618Z"
    }
   },
   "outputs": [],
   "source": [
    "# üî¢ ÏàòÏπòÌòï\n",
    "num_cols = [\n",
    "    \"Í∏∞Ïò®(¬∞C)\",\n",
    "    \"ÌíçÏÜç_ms\",\n",
    "    \"dep_hour\",\n",
    "    \"dep_weekday\",\n",
    "    \"is_weekend\"\n",
    "]\n",
    "num_cols = [c for c in num_cols if c in df.columns]\n",
    "\n",
    "# üè∑ Î≤îÏ£ºÌòï\n",
    "cat_cols = [\n",
    "    \"Í≥µÌï≠Î™Ö\",\n",
    "    \"Ï∂úÎ∞úÏßÄ\",\n",
    "    \"ÎèÑÏ∞©ÏßÄ\",\n",
    "    \"flight_type\"\n",
    "]\n",
    "cat_cols = [c for c in cat_cols if c in df.columns]\n",
    "\n",
    "X_cols = num_cols + cat_cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0d0127c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-21T08:28:16.466700Z",
     "start_time": "2026-01-21T08:28:15.050552Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 2275147 Test: 568787\n"
     ]
    }
   ],
   "source": [
    "df = df.sort_values(\"departure_datetime\")\n",
    "split_date = df[\"departure_datetime\"].quantile(0.8)\n",
    "\n",
    "train_df = df[df[\"departure_datetime\"] <= split_date]\n",
    "test_df  = df[df[\"departure_datetime\"] > split_date]\n",
    "\n",
    "X_train = train_df[X_cols]\n",
    "y_train = train_df[\"is_delay\"]\n",
    "\n",
    "X_test  = test_df[X_cols]\n",
    "y_test  = test_df[\"is_delay\"]\n",
    "\n",
    "print(\"Train:\", len(train_df), \"Test:\", len(test_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a493f4ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-21T08:32:05.457634Z",
     "start_time": "2026-01-21T08:28:16.467694Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\envs\\4vector\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Logistic (threshold=0.4)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.38      0.53    422243\n",
      "           1       0.31      0.82      0.45    146544\n",
      "\n",
      "    accuracy                           0.49    568787\n",
      "   macro avg       0.59      0.60      0.49    568787\n",
      "weighted avg       0.72      0.49      0.51    568787\n",
      "\n",
      "ROC-AUC: 0.6474615621075573\n",
      "PR-AUC : 0.3721759150947776\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "num_pipe = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\"))\n",
    "])\n",
    "\n",
    "cat_pipe = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"UNKNOWN\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\", sparse=True))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"num\", num_pipe, num_cols),\n",
    "    (\"cat\", cat_pipe, cat_cols)\n",
    "])\n",
    "\n",
    "logistic = Pipeline([\n",
    "    (\"prep\", preprocessor),\n",
    "    (\"clf\", LogisticRegression(\n",
    "        max_iter=3000,\n",
    "        class_weight=\"balanced\",\n",
    "        n_jobs=-1\n",
    "    ))\n",
    "])\n",
    "\n",
    "logistic.fit(X_train, y_train)\n",
    "\n",
    "log_prob = logistic.predict_proba(X_test)[:, 1]\n",
    "log_pred = (log_prob >= 0.4).astype(int)\n",
    "\n",
    "print(\"\\nüìä Logistic (threshold=0.4)\")\n",
    "print(classification_report(y_test, log_pred))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, log_prob))\n",
    "print(\"PR-AUC :\", average_precision_score(y_test, log_prob))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f61b0155",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-21T08:32:34.971551Z",
     "start_time": "2026-01-21T08:32:05.458871Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\envs\\4vector\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä XGBoost (threshold=0.4)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.43      0.57    422243\n",
      "           1       0.34      0.83      0.48    146544\n",
      "\n",
      "    accuracy                           0.53    568787\n",
      "   macro avg       0.61      0.63      0.53    568787\n",
      "weighted avg       0.74      0.53      0.55    568787\n",
      "\n",
      "ROC-AUC: 0.6854605778465136\n",
      "PR-AUC : 0.4262482943255317\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb = XGBClassifier(\n",
    "    n_estimators=400,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "\n",
    "    scale_pos_weight=(y_train == 0).sum() / (y_train == 1).sum(),\n",
    "    objective=\"binary:logistic\",\n",
    "    eval_metric=\"aucpr\",\n",
    "    tree_method=\"hist\",\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "xgb_model = Pipeline([\n",
    "    (\"prep\", preprocessor),\n",
    "    (\"xgb\", xgb)\n",
    "])\n",
    "\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "xgb_prob = xgb_model.predict_proba(X_test)[:, 1]\n",
    "xgb_pred = (xgb_prob >= 0.4).astype(int)\n",
    "\n",
    "print(\"\\nüìä XGBoost (threshold=0.4)\")\n",
    "print(classification_report(y_test, xgb_pred))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, xgb_prob))\n",
    "print(\"PR-AUC :\", average_precision_score(y_test, xgb_prob))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ad79f84",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-21T08:33:07.720649Z",
     "start_time": "2026-01-21T08:32:34.972551Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 336343, number of negative: 1938804\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014151 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 661\n",
      "[LightGBM] [Info] Number of data points in the train set: 2275147, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "\n",
      "üìä LightGBM (threshold=0.4)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.48      0.62    422243\n",
      "           1       0.35      0.80      0.49    146544\n",
      "\n",
      "    accuracy                           0.56    568787\n",
      "   macro avg       0.61      0.64      0.55    568787\n",
      "weighted avg       0.74      0.56      0.58    568787\n",
      "\n",
      "ROC-AUC: 0.7059227082554224\n",
      "PR-AUC : 0.4578427366604109\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# LightGBMÏö© category Î≥ÄÌôò\n",
    "for c in cat_cols:\n",
    "    df[c] = df[c].astype(\"category\")\n",
    "\n",
    "train_df = df[df[\"departure_datetime\"] <= split_date]\n",
    "test_df  = df[df[\"departure_datetime\"] > split_date]\n",
    "\n",
    "X_train_lgb = train_df[X_cols]\n",
    "y_train_lgb = train_df[\"is_delay\"]\n",
    "\n",
    "X_test_lgb  = test_df[X_cols]\n",
    "y_test_lgb  = test_df[\"is_delay\"]\n",
    "\n",
    "lgbm = LGBMClassifier(\n",
    "    n_estimators=500,\n",
    "    learning_rate=0.05,\n",
    "    num_leaves=64,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "\n",
    "    class_weight=\"balanced\",\n",
    "    objective=\"binary\",\n",
    "    metric=\"aucpr\",\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "lgbm.fit(\n",
    "    X_train_lgb,\n",
    "    y_train_lgb,\n",
    "    categorical_feature=cat_cols\n",
    ")\n",
    "\n",
    "lgb_prob = lgbm.predict_proba(X_test_lgb)[:, 1]\n",
    "lgb_pred = (lgb_prob >= 0.4).astype(int)\n",
    "\n",
    "print(\"\\nüìä LightGBM (threshold=0.4)\")\n",
    "print(classification_report(y_test_lgb, lgb_pred))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test_lgb, lgb_prob))\n",
    "print(\"PR-AUC :\", average_precision_score(y_test_lgb, lgb_prob))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da23d4b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-21T08:33:08.617298Z",
     "start_time": "2026-01-21T08:33:07.722600Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>ROC-AUC</th>\n",
       "      <th>PR-AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic</td>\n",
       "      <td>0.647462</td>\n",
       "      <td>0.372176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.685461</td>\n",
       "      <td>0.426248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.705923</td>\n",
       "      <td>0.457843</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Model   ROC-AUC    PR-AUC\n",
       "0  Logistic  0.647462  0.372176\n",
       "1   XGBoost  0.685461  0.426248\n",
       "2  LightGBM  0.705923  0.457843"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary = pd.DataFrame([\n",
    "    [\"Logistic\", roc_auc_score(y_test, log_prob), average_precision_score(y_test, log_prob)],\n",
    "    [\"XGBoost\",  roc_auc_score(y_test, xgb_prob), average_precision_score(y_test, xgb_prob)],\n",
    "    [\"LightGBM\", roc_auc_score(y_test_lgb, lgb_prob), average_precision_score(y_test_lgb, lgb_prob)]\n",
    "], columns=[\"Model\", \"ROC-AUC\", \"PR-AUC\"])\n",
    "\n",
    "summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110d4d79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2e4622",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "4vector(ipykernel)",
   "language": "python",
   "name": "4vector"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
